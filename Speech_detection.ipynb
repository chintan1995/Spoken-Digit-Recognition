{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwoTWIysaNmc"
   },
   "source": [
    "<pre><font size=6>Spoken Digit Recognition</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPO3mjDDaNmf"
   },
   "source": [
    "<pre>\n",
    "Input - speech signal, output - digit number\n",
    "\n",
    "1. Reading the dataset. and Preprocess the data set. Detailed instrctions are given below.\n",
    "2. Training the LSTM with RAW data\n",
    "3. Converting to spectrogram and Training the LSTM network\n",
    "4. Creating the augmented data and doing step 2 and 3 again.  \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vII0VjTMLlRn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'recordings.zip' not in os.listdir(): \n",
    "    !wget https://www.dropbox.com/s/3o07dl8cemw887v/recordings.zip\n",
    "    get_ipython().system_raw(\"7z x recordings.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_qGuPcj-aNmh",
    "outputId": "715aa2ff-afae-417d-ef24-b8e4e8c7ec52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "##if you need any imports you can do that here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDBcl_PUaNmp"
   },
   "outputs": [],
   "source": [
    "#read the all file names in the recordings folder given by us\n",
    "#(if you get entire path, it is very useful in future)\n",
    "#save those files names as list in \"all_files\"\n",
    "root = pathlib.Path(\"recordings\")\n",
    "rec_paths = list(root.rglob(\"*.wav*\"))\n",
    "all_files = [str(path) for path in rec_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "yaqpL8tKQQ7o",
    "outputId": "776e2599-9ac4-4e0d-d50a-1b15d03726bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhvSIN6raNm3"
   },
   "source": [
    "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "You can get the label from the first letter of name.  \n",
    "Eg: 0_jackson_0 --> 0  \n",
    "0_jackson_43 --> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWP6vXBeaNm3"
   },
   "outputs": [],
   "source": [
    "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
    "#You can get the label from the first letter of name.  \n",
    "#Eg: 0_jackson_0 --> 0  \n",
    "#0_jackson_43 --> 0\n",
    "label_lst = []\n",
    "for p in all_files:\n",
    "    label_name =  int(p.split(\"/\")[1].split(\"_\")[0])\n",
    "    label_lst.append(label_name)\n",
    "df_audio = pd.DataFrame(list(zip(all_files, label_lst)), columns =['path', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "5ZpuaGuJaNm8",
    "outputId": "e9cfe37d-e7a9-45cb-d109-f6b35d6b43b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    2000 non-null   object\n",
      " 1   label   2000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#info\n",
    "df_audio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlfssCc3aNnL"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ448aENaNnR"
   },
   "source": [
    "<pre><font size=4>Train and Validation split</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "aXGbeNKeXfPC",
    "outputId": "4f821c2a-638e-47aa-b3c2-0d7f56d294ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>recordings/4_yweweler_47.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>recordings/3_yweweler_26.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>recordings/4_nicolas_25.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>recordings/9_yweweler_43.wav</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>recordings/4_yweweler_15.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path  label\n",
       "766   recordings/4_yweweler_47.wav      4\n",
       "182   recordings/3_yweweler_26.wav      3\n",
       "1763   recordings/4_nicolas_25.wav      4\n",
       "1814  recordings/9_yweweler_43.wav      9\n",
       "596   recordings/4_yweweler_15.wav      4"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSPy-Ln6aNnS"
   },
   "outputs": [],
   "source": [
    "#split the data into train and validation and save in X_train, X_test, y_train, y_test\n",
    "#use stratify sampling\n",
    "#use random state of 45\n",
    "#use test size of 30%\n",
    "X = df_audio['path']\n",
    "y = df_audio['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.30, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vTw1HlOkakhF",
    "outputId": "17e06362-799a-47e7-840f-79d897c0f721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordings/6_yweweler_26.wav\n"
     ]
    }
   ],
   "source": [
    "for i in X_train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGhh-39vaNnb"
   },
   "source": [
    "<pre><font size=4>Preprocessing</font>\n",
    "\n",
    "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i99JacQSaNnc"
   },
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "def load_wav(x, get_duration=True):\n",
    "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
    "    #loading the wav file with sampling rate of 22050\n",
    "    samples, sample_rate = librosa.load(x, sr=22050)\n",
    "    if get_duration:\n",
    "        duration = librosa.get_duration(samples, sample_rate)\n",
    "        return [samples, duration]\n",
    "    else:\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "36ae6015f4234b47a71608de2d50056c",
      "76c8871ca47543408de273192ceb5beb",
      "ebaa5ac8c77a423a968caf2fb303404e",
      "21b558eeb41641fc8e9aca53f1f54acd",
      "b9191a5e73854e5aa2a5cee1946a044a",
      "3d7b729bb25b4c0085f5ec3f2c28b2e6",
      "583178cee17d4f3a9d801dadd45a6f7e",
      "75bcf38542a44017828f85386d0b5c81",
      "10fd7456dbaf4ce3a2bafadad598902c",
      "6541802d06a349428b4b16c598bfe3f0",
      "e8a039fa1fb743f398c4bccc7824f477",
      "559bde2d34df4679aaa4e61c2fd12856",
      "30682612f8cb4a56811a0fd0f01d3f70",
      "40cb533aff9648768b5a4c70511dcab1",
      "3cca56fa5ee44afc9ba574859e7f9e78",
      "b1d281855501473eb4ecc8f10215e549"
     ]
    },
    "id": "Rx97f8GGaNnh",
    "outputId": "3f06be22-dc05-4fbe-d537-31604af2dfd5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ae6015f4234b47a71608de2d50056c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1400.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fd7456dbaf4ce3a2bafadad598902c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#use load_wav function that was written above to get every wave. \n",
    "#save it in X_train_processed and X_test_processed\n",
    "# X_train_processed/X_test_processed should be dataframes with two columns(raw_data, duration) with same index of X_train/y_train\n",
    "X_train_processed_lst = []\n",
    "X_test_processed_lst = []\n",
    "\n",
    "for path in tqdm(X_train):\n",
    "    s_d = load_wav(path)\n",
    "    X_train_processed_lst.append(s_d)\n",
    "\n",
    "for path in tqdm(X_test):\n",
    "    s_d = load_wav(path)\n",
    "    X_test_processed_lst.append(s_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKDkfFdmbo2a"
   },
   "outputs": [],
   "source": [
    "X_train_processed = pd.DataFrame(X_train_processed_lst, columns =['raw_data', 'duration'])\n",
    "X_test_processed = pd.DataFrame(X_test_processed_lst, columns =['raw_data', 'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2Oj17BwUKZDI",
    "outputId": "8eb199e4-05ad-4945-8913-92df3b2d674f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'recordings/5_theo_28.wav'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "x7cKp1-DHDxV",
    "outputId": "ad3eaa20-af5c-4ce2-bc27-33974cf9a310"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.5782520e-04,  1.6368195e-04,  1.6087637e-04, ...,\n",
       "        -5.7159035e-05, -4.8506179e-05,  0.0000000e+00], dtype=float32),\n",
       " 0.2821315192743764]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_wav('recordings/5_yweweler_17.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "l4lmPHnCHBg_",
    "outputId": "e62322ae-4486-40b7-e5cb-d8e40941a7fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.00067993, -0.0014941 , -0.00177168, ..., -0.00064158,\n",
       "        -0.00043909,  0.        ], dtype=float32), 0.3805442176870748]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed_lst[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "BY2au9P4b9PC",
    "outputId": "f727e6f0-cec2-458a-c844-6dd182147bc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.00021709508, -0.00028584333, -0.0003213715...</td>\n",
       "      <td>0.192789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.00024565606, 0.00023941231, 0.00021052365, ...</td>\n",
       "      <td>0.339501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9.440214e-05, 0.00016939559, 0.00022562861, 0...</td>\n",
       "      <td>0.279637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.00067992735, -0.0014940997, -0.00177168, -...</td>\n",
       "      <td>0.380544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.00018011512, 0.00013778498, 4.1579457e-05, ...</td>\n",
       "      <td>0.370884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data  duration\n",
       "0  [-0.00021709508, -0.00028584333, -0.0003213715...  0.192789\n",
       "1  [0.00024565606, 0.00023941231, 0.00021052365, ...  0.339501\n",
       "2  [9.440214e-05, 0.00016939559, 0.00022562861, 0...  0.279637\n",
       "3  [-0.00067992735, -0.0014940997, -0.00177168, -...  0.380544\n",
       "4  [0.00018011512, 0.00013778498, 4.1579457e-05, ...  0.370884"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "U5bGa69Bb-5n",
    "outputId": "43192404-9ac7-40f5-fa40-0fd795f552c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2.7298905e-05, -0.00042524404, -0.00047223858...</td>\n",
       "      <td>0.245034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.012453565, -0.011977133, -0.008346662, -0....</td>\n",
       "      <td>0.369388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0012325012, 0.0051624463, 0.007153227, 0.00...</td>\n",
       "      <td>0.225170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.0071184835, -0.010403867, -0.010893734, -0...</td>\n",
       "      <td>0.470385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.00028326915, 0.0003435616, 0.0003327661, 0....</td>\n",
       "      <td>0.446395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_data  duration\n",
       "0  [2.7298905e-05, -0.00042524404, -0.00047223858...  0.245034\n",
       "1  [-0.012453565, -0.011977133, -0.008346662, -0....  0.369388\n",
       "2  [0.0012325012, 0.0051624463, 0.007153227, 0.00...  0.225170\n",
       "3  [-0.0071184835, -0.010403867, -0.010893734, -0...  0.470385\n",
       "4  [0.00028326915, 0.0003435616, 0.0003327661, 0....  0.446395"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "duQZPQevaNno",
    "outputId": "d78ca881-089b-4f17-95d1-2eb57b1fed8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b3db702b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the histogram of the duration for trian\n",
    "X_train_processed.plot.hist('duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "vvLhm1AqaNny",
    "outputId": "b60c5d21-f87f-4410-d1cf-06558bd037eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th percentile is 0.1436281179138322\n",
      "10 th percentile is 0.2581269841269841\n",
      "20 th percentile is 0.3010884353741497\n",
      "30 th percentile is 0.33136961451247166\n",
      "40 th percentile is 0.35846712018140586\n",
      "50 th percentile is 0.3907256235827664\n",
      "60 th percentile is 0.4185578231292517\n",
      "70 th percentile is 0.4470702947845805\n",
      "80 th percentile is 0.48386394557823137\n",
      "90 th percentile is 0.5536734693877551\n",
      "100 th percentile is 2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "#print 0 to 100 percentile values with step size of 10 for train data duration. \n",
    "for i in range(0,101,10):\n",
    "    print(i,\"th percentile is\",np.percentile(X_train_processed[['duration']].values, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rSlVQh4CaNn2",
    "outputId": "507935ec-e9e7-4609-b8c8-e4dca6e3dcd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 th percentile is 0.5536734693877551\n",
      "91 th percentile is 0.5642412698412701\n",
      "92 th percentile is 0.5761396825396827\n",
      "93 th percentile is 0.5864027210884358\n",
      "94 th percentile is 0.6033333333333333\n",
      "95 th percentile is 0.6208095238095238\n",
      "96 th percentile is 0.6379374149659863\n",
      "97 th percentile is 0.6549514739229023\n",
      "98 th percentile is 0.6822975056689342\n",
      "99 th percentile is 0.7908185941043082\n",
      "100 th percentile is 2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "##print 90 to 100 percentile values with step size of 1. \n",
    "for i in range(90,101):\n",
    "    print(i,\"th percentile is\",np.percentile(X_train_processed[['duration']].values, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "5OQVOrY7qkUn",
    "outputId": "8ab2b858-02d0-4349-8cef-7eb8ad181f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.1 th percentile is 0.8114687528344657\n",
      "99.2 th percentile is 0.8204019954648525\n",
      "99.3 th percentile is 0.8279474829931972\n",
      "99.4 th percentile is 0.8419322448979643\n",
      "99.5 th percentile is 0.8556700680272102\n",
      "99.6 th percentile is 0.8604631292517007\n",
      "99.7 th percentile is 0.8644408616780039\n",
      "99.8 th percentile is 0.871304671201814\n",
      "99.9 th percentile is 1.6707764625851824\n",
      "100 th percentile is 2.282766439909297\n"
     ]
    }
   ],
   "source": [
    "# printing 99 to 100 percentile values with step size of 0.1\n",
    "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
    "    print(i,\"th percentile is\",np.percentile(X_train_processed[['duration']].values, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cux3_jfcaNoM"
   },
   "source": [
    "<pre>Based on the above analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset. \n",
    "\n",
    "While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
    "\n",
    "Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
    "\n",
    "Also create a masking vector for train and test. \n",
    "\n",
    "masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voqSEyvcaNoO"
   },
   "outputs": [],
   "source": [
    "max_length  = 17640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1-_r20BaNoW"
   },
   "outputs": [],
   "source": [
    "# Creating Padding\n",
    "def pad_sequence(data, max_length): # This 'data' will be a pandas Series\n",
    "    X_pad_seq = []\n",
    "    for idx in range(len(data)):\n",
    "        truncated = data[idx][:max_length]\n",
    "        pad_this_much = max_length - len(truncated)\n",
    "        X_pad_seq.append(np.pad(truncated, ((0,pad_this_much)), mode='constant', constant_values=0))\n",
    "    X_pad_seq = np.array(X_pad_seq)\n",
    "    return X_pad_seq\n",
    "\n",
    "# Creating Mask\n",
    "def mask_padded_sequence(padded_sequence):\n",
    "    unmasked_embedding = tf.cast(tf.tile(tf.expand_dims(padded_sequence, axis=-1), [1, 1, 1]), tf.float32)\n",
    "    masked_embedding  = tf.keras.layers.Masking()(unmasked_embedding)\n",
    "    X_train_mask = masked_embedding._keras_mask\n",
    "    return X_train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZJFzI02mqMk"
   },
   "outputs": [],
   "source": [
    "X_train_pad_seq = pad_sequence(X_train_processed['raw_data'], max_length)\n",
    "X_test_pad_seq = pad_sequence(X_test_processed['raw_data'], max_length)\n",
    "\n",
    "X_train_mask = mask_padded_sequence(X_train_pad_seq)\n",
    "X_test_mask = mask_padded_sequence(X_test_pad_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0kaYQ1jaNop"
   },
   "source": [
    "# **1. Giving Raw data directly** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGHxh3jTaNoq"
   },
   "source": [
    "<pre>\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_pad_seq, X_train_mask and y_train  \n",
    "Test data: X_test_pad_seq, X_test_mask and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_pad_seq\" as input, \"X_train_mask\" as mask input. Read LSTM documentation(https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) in tensorflow to know more about mask and also https://www.tensorflow.org/guide/keras/masking_and_padding \n",
    "2. Get the final output of the LSTM and give it to Dense layer and then give it to Dense layer of size 10 (because we have 10 outputs) and then compile with the sparse categorical cross entropy( because we are not converting it to one hot vectors). \n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTq2it7nRFuX"
   },
   "outputs": [],
   "source": [
    "## as discussed above, please write the LSTM\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_X = Input(shape=(max_length,1), name=\"Input_X\")\n",
    "input_mask = Input(shape=max_length, name=\"Input_Mask\", dtype='bool')\n",
    "lstm = LSTM(units=64)(inputs=input_X, mask=input_mask)\n",
    "dense = Dense(units=32, activation='relu')(lstm)\n",
    "dense = BatchNormalization()(dense)\n",
    "output = Dense(units=10, activation='softmax', name=\"Output\")(dense)\n",
    "\n",
    "model = Model(inputs=[input_X,input_mask], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "q8cgZFl8UT4p",
    "outputId": "d199d5a2-a454-4e5e-b5e9-1103c7275924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_X (InputLayer)            [(None, 17640, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_Mask (InputLayer)         [(None, 17640)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           16896       Input_X[0][0]                    \n",
      "                                                                 Input_Mask[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           2080        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Output (Dense)                  (None, 10)           330         batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 19,434\n",
      "Trainable params: 19,370\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKTsqaddVZ8I"
   },
   "outputs": [],
   "source": [
    "# For more info on ModelCheckpoint, refer https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_path = \"BEST_MODEL_1.hdfs\"\n",
    "checkpoint_1 = ModelCheckpoint(filepath=model_path, monitor='val_micro_f1',verbose=1, mode='max', save_best_only=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# https://stackoverflow.com/a/42963385/7697658\n",
    "lrschedule_1 = ReduceLROnPlateau(monitor='val_micro_f1', patience=2, mode='max', verbose=1, factor=0.50)\n",
    "\n",
    "import datetime\n",
    "log_dir=\"logs/1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=True)\n",
    "\n",
    "def f1_score_micro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average = 'micro')\n",
    "    \n",
    "def micro_f1(y_true, y_proba):\n",
    "    y_pred = tf.math.argmax(y_proba,axis=1)\n",
    "    return tf.py_function(f1_score_micro, (y_true,y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RQzQAGo6seK"
   },
   "outputs": [],
   "source": [
    "!rm -r logs\n",
    "!rm -r model_1_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "MzpPjxvHaNpJ",
    "outputId": "d4cdfbc7-8190-4c7f-d4a8-343f16fa8761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.3038 - micro_f1: 0.0793\n",
      "Epoch 00001: val_micro_f1 improved from -inf to 0.10088, saving model to BEST_MODEL_1.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_1.hdfs/assets\n",
      "44/44 [==============================] - 43s 967ms/step - loss: 2.3038 - micro_f1: 0.0793 - val_loss: 2.3027 - val_micro_f1: 0.1009\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.3018 - micro_f1: 0.0843\n",
      "Epoch 00002: val_micro_f1 did not improve from 0.10088\n",
      "44/44 [==============================] - 32s 738ms/step - loss: 2.3018 - micro_f1: 0.0843 - val_loss: 2.3029 - val_micro_f1: 0.0998\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.3024 - micro_f1: 0.0959\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00003: val_micro_f1 did not improve from 0.10088\n",
      "44/44 [==============================] - 32s 717ms/step - loss: 2.3024 - micro_f1: 0.0959 - val_loss: 2.3030 - val_micro_f1: 0.0998\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.3011 - micro_f1: 0.0956\n",
      "Epoch 00004: val_micro_f1 improved from 0.10088 to 0.12500, saving model to BEST_MODEL_1.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_1.hdfs/assets\n",
      "44/44 [==============================] - 41s 930ms/step - loss: 2.3011 - micro_f1: 0.0956 - val_loss: 2.3028 - val_micro_f1: 0.1250\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.3002 - micro_f1: 0.1009\n",
      "Epoch 00005: val_micro_f1 did not improve from 0.12500\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 2.3002 - micro_f1: 0.1009 - val_loss: 2.3027 - val_micro_f1: 0.1195\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.3007 - micro_f1: 0.1013\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00006: val_micro_f1 did not improve from 0.12500\n",
      "44/44 [==============================] - 32s 725ms/step - loss: 2.3007 - micro_f1: 0.1013 - val_loss: 2.3033 - val_micro_f1: 0.0998\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.2998 - micro_f1: 0.0949\n",
      "Epoch 00007: val_micro_f1 did not improve from 0.12500\n",
      "44/44 [==============================] - 32s 723ms/step - loss: 2.2998 - micro_f1: 0.0949 - val_loss: 2.3036 - val_micro_f1: 0.0998\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.3002 - micro_f1: 0.0980\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00008: val_micro_f1 did not improve from 0.12500\n",
      "44/44 [==============================] - 32s 729ms/step - loss: 2.3002 - micro_f1: 0.0980 - val_loss: 2.3034 - val_micro_f1: 0.0998\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.2997 - micro_f1: 0.1027\n",
      "Epoch 00009: val_micro_f1 did not improve from 0.12500\n",
      "44/44 [==============================] - 32s 732ms/step - loss: 2.2997 - micro_f1: 0.1027 - val_loss: 2.3031 - val_micro_f1: 0.1140\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 2.2999 - micro_f1: 0.0985\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00010: val_micro_f1 did not improve from 0.12500\n",
      "44/44 [==============================] - 32s 728ms/step - loss: 2.2999 - micro_f1: 0.0985 - val_loss: 2.3031 - val_micro_f1: 0.1053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f393f77df98>"
      ]
     },
     "execution_count": 164,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "#callbacks=[lrschedule_1, checkpoint_1, tensorboard_callback]\n",
    "#validation_data=((X_test_pad_seq,X_test_mask), y_test)\n",
    "#X_train_pad_seq, X_train_mask, X_test_pad_seq, X_test_mask\n",
    "opt = Adam(0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=[micro_f1])\n",
    "model.fit(x=[X_train_pad_seq,X_train_mask], y=y_train, validation_data=([X_test_pad_seq,X_test_mask], y_test), \\\n",
    "          epochs=10, verbose=True, callbacks=[lrschedule_1, checkpoint_1, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky4PVWkayFw5"
   },
   "outputs": [],
   "source": [
    "!zip -r logs.zip logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "VXpnCIfOpdUM",
    "outputId": "18cead88-5397-4c73-8d00-4aa2b508ae07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 6s 298ms/step - loss: 2.3028 - micro_f1: 0.1250\n",
      "Best Micro F1 score model 1= 0.125\n"
     ]
    }
   ],
   "source": [
    "best_model_1 = tf.keras.models.load_model('BEST_MODEL_1.hdfs', custom_objects={'f1_score_micro':f1_score_micro,'micro_f1':micro_f1})\n",
    "best_f1_model_1 = best_model_1.evaluate([X_test_pad_seq,X_test_mask], y_test)[1]\n",
    "print(\"Best Micro F1 score model 1=\",best_f1_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Fwk0X4zaNpR"
   },
   "source": [
    "# **2. Converting into spectrogram and giving spectrogram data as input**  \n",
    "<pre>\n",
    "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
    "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. read more about this in <a href=https://pnsn.org/spectrograms/what-is-a-spectrogram>https://pnsn.org/spectrograms/what-is-a-spectrogram</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nb5AGzTjaNpS"
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "0058c742827f431596a0188606863ddf",
      "6447d1f9ba9845b5b478894aa2da2244",
      "477852c6372a46edb6eb9f3c8ad99adb",
      "00f0f02d35f34fb3b9f6b869cc44214a",
      "5ae570077bf34817a4bdb4949d3a16c5",
      "d9852c5369234c0ba459e0c374ab5e02",
      "c7aebf186254440f8053e0d442a1493f",
      "59bb92fb80c64ca59126d96514c56ea4",
      "be099a8dc7804a2aa32f0f921aa37e2a",
      "c84c5c617c124473b362bb59fa2cb71d",
      "d735fc20e3084576ade2c492e4cbc4f4",
      "4237a39d5ccb4cfdb676bc0a2f60f177",
      "986386b7a8b4483999e233c91175065e",
      "69ad04d1988f40ad8928b48c3852f1cc",
      "0f00f5a08c0b4193b83f9cd63ee838cb",
      "035f1d8993324ca2a445c7c2710d2fa5"
     ]
    },
    "id": "B__rN4RjaNpc",
    "outputId": "c6b22975-32b6-4dfb-fea7-ac0c1cad71ec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0058c742827f431596a0188606863ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1400.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be099a8dc7804a2aa32f0f921aa37e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad_seq.\n",
    "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
    "def get_spectogram_data(X_pad_seq):\n",
    "    X_spectrogram = []\n",
    "    for raw_data in tqdm(X_pad_seq):\n",
    "        spectogram_data = convert_to_spectrogram(raw_data)\n",
    "        X_spectrogram.append(spectogram_data)\n",
    "    return np.array(X_spectrogram)\n",
    "\n",
    "\n",
    "X_train_pad_seq = pad_sequence(X_train_processed['raw_data'], max_length)\n",
    "X_test_pad_seq = pad_sequence(X_test_processed['raw_data'], max_length)\n",
    "\n",
    "X_train_spectrogram = get_spectogram_data(X_train_pad_seq)\n",
    "X_test_spectrogram = get_spectogram_data(X_test_pad_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxlEVyIYaNpt"
   },
   "source": [
    "<pre>\n",
    "Now we have\n",
    "\n",
    "Train data: X_train_spectrogram and y_train  \n",
    "Test data: X_test_spectrogram and y_test   \n",
    "\n",
    "We will create a LSTM model which takes this input. \n",
    "\n",
    "Task:\n",
    "\n",
    "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
    "2. Average the output of every time step and give this to the Dense layer of any size. \n",
    "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "IaQjaiiGaNpv",
    "outputId": "9a93be1f-7cf8-4e08-ecbc-41c9dcd7c14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 128)\n",
      "(None, 1, 64, 128)\n",
      "(None, 1, 128, 64)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_X = Input(shape=(64,35), name=\"Input_X\")\n",
    "lstm = LSTM(units=128, return_sequences=True)(inputs=input_X)\n",
    "print(lstm.shape)\n",
    "lstm = tf.expand_dims(lstm, axis=1)\n",
    "print(lstm.shape)\n",
    "lstm = tf.transpose(lstm, perm=[0,1,3,2])\n",
    "print(lstm.shape)\n",
    "avg_timesteps = GlobalAveragePooling2D()(lstm)\n",
    "print(avg_timesteps.shape)\n",
    "avg_timesteps = BatchNormalization()(avg_timesteps)\n",
    "dense = Dense(units=64, activation='relu', kernel_initializer=initializers.GlorotUniform(seed=0), kernel_regularizer=regularizers.l2())(avg_timesteps)\n",
    "output = Dense(units=10, activation='softmax', name=\"Output\")(dense)\n",
    "\n",
    "model = Model(inputs=input_X, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "862fP2e-aNp3",
    "outputId": "138c67fe-c116-41e2-b212-6a0345f1186a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_X (InputLayer)         [(None, 64, 35)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64, 128)           83968     \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 1, 64, 128)]      0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Transpose (Tenso [(None, 1, 128, 64)]      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 89,034\n",
      "Trainable params: 88,906\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtMsbGs3aNp_"
   },
   "outputs": [],
   "source": [
    "# For more info on ModelCheckpoint, refer https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_path = \"BEST_MODEL_2.hdfs\"\n",
    "checkpoint_1 = ModelCheckpoint(filepath=model_path, monitor='val_micro_f1',verbose=1, mode='max', save_best_only=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# https://stackoverflow.com/a/42963385/7697658\n",
    "lrschedule_1 = ReduceLROnPlateau(monitor='val_micro_f1', min_lr=0.000001, patience=2, mode='max', verbose=1, factor=0.50)\n",
    "\n",
    "import datetime\n",
    "log_dir=\"logs/2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=True)\n",
    "\n",
    "def f1_score_micro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average = 'micro')\n",
    "    \n",
    "def micro_f1(y_true, y_proba):\n",
    "    y_pred = tf.math.argmax(y_proba,axis=1)\n",
    "    return tf.py_function(f1_score_micro, (y_true,y_pred), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loeMa2-LYvhC"
   },
   "outputs": [],
   "source": [
    "!rm -r logs\n",
    "!rm -r model_2_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "81lU6hjOY01u",
    "outputId": "9e02abe2-0648-4ad2-d369-8e22715a7bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/44 [>.............................] - ETA: 3s - loss: 3.0568 - micro_f1: 0.0781    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0165s vs `on_train_batch_end` time: 0.1544s). Check your callbacks.\n",
      "43/44 [============================>.] - ETA: 0s - loss: 2.6917 - micro_f1: 0.2500\n",
      "Epoch 00001: val_micro_f1 improved from -inf to 0.26700, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 5s 114ms/step - loss: 2.6863 - micro_f1: 0.2538 - val_loss: 2.8029 - val_micro_f1: 0.2670\n",
      "Epoch 2/100\n",
      "40/44 [==========================>...] - ETA: 0s - loss: 2.0228 - micro_f1: 0.4828\n",
      "Epoch 00002: val_micro_f1 improved from 0.26700 to 0.28070, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 5s 119ms/step - loss: 1.9932 - micro_f1: 0.4950 - val_loss: 2.6613 - val_micro_f1: 0.2807\n",
      "Epoch 3/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 1.5693 - micro_f1: 0.6417\n",
      "Epoch 00003: val_micro_f1 improved from 0.28070 to 0.33717, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 101ms/step - loss: 1.5694 - micro_f1: 0.6432 - val_loss: 2.5016 - val_micro_f1: 0.3372\n",
      "Epoch 4/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 1.3264 - micro_f1: 0.7100\n",
      "Epoch 00004: val_micro_f1 improved from 0.33717 to 0.34868, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 1.3223 - micro_f1: 0.7128 - val_loss: 2.3380 - val_micro_f1: 0.3487\n",
      "Epoch 5/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 1.1270 - micro_f1: 0.7842\n",
      "Epoch 00005: val_micro_f1 improved from 0.34868 to 0.56469, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 99ms/step - loss: 1.1223 - micro_f1: 0.7874 - val_loss: 2.0579 - val_micro_f1: 0.5647\n",
      "Epoch 6/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.9954 - micro_f1: 0.8125\n",
      "Epoch 00006: val_micro_f1 improved from 0.56469 to 0.59978, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 5s 124ms/step - loss: 0.9997 - micro_f1: 0.8101 - val_loss: 1.9051 - val_micro_f1: 0.5998\n",
      "Epoch 7/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.8966 - micro_f1: 0.8416\n",
      "Epoch 00007: val_micro_f1 did not improve from 0.59978\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.8980 - micro_f1: 0.8414 - val_loss: 1.7501 - val_micro_f1: 0.5927\n",
      "Epoch 8/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.8128 - micro_f1: 0.8597\n",
      "Epoch 00008: val_micro_f1 improved from 0.59978 to 0.71656, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 0.8153 - micro_f1: 0.8591 - val_loss: 1.5053 - val_micro_f1: 0.7166\n",
      "Epoch 9/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.7662 - micro_f1: 0.8597\n",
      "Epoch 00009: val_micro_f1 improved from 0.71656 to 0.73300, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 99ms/step - loss: 0.7652 - micro_f1: 0.8601 - val_loss: 1.3503 - val_micro_f1: 0.7330\n",
      "Epoch 10/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.7361 - micro_f1: 0.8638\n",
      "Epoch 00010: val_micro_f1 did not improve from 0.73300\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.7364 - micro_f1: 0.8653 - val_loss: 1.1873 - val_micro_f1: 0.7105\n",
      "Epoch 11/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.7106 - micro_f1: 0.8757\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00011: val_micro_f1 did not improve from 0.73300\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.7143 - micro_f1: 0.8729 - val_loss: 1.1058 - val_micro_f1: 0.7237\n",
      "Epoch 12/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.6159 - micro_f1: 0.9137\n",
      "Epoch 00012: val_micro_f1 improved from 0.73300 to 0.81250, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 0.6147 - micro_f1: 0.9143 - val_loss: 0.8684 - val_micro_f1: 0.8125\n",
      "Epoch 13/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.6047 - micro_f1: 0.9055\n",
      "Epoch 00013: val_micro_f1 improved from 0.81250 to 0.88103, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 6s 126ms/step - loss: 0.6049 - micro_f1: 0.9036 - val_loss: 0.7334 - val_micro_f1: 0.8810\n",
      "Epoch 14/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.5689 - micro_f1: 0.9107\n",
      "Epoch 00014: val_micro_f1 improved from 0.88103 to 0.91228, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 0.5706 - micro_f1: 0.9110 - val_loss: 0.6216 - val_micro_f1: 0.9123\n",
      "Epoch 15/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.5764 - micro_f1: 0.9137\n",
      "Epoch 00015: val_micro_f1 improved from 0.91228 to 0.92105, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 101ms/step - loss: 0.5744 - micro_f1: 0.9138 - val_loss: 0.5976 - val_micro_f1: 0.9211\n",
      "Epoch 16/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.5470 - micro_f1: 0.9172\n",
      "Epoch 00016: val_micro_f1 improved from 0.92105 to 0.92763, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 0.5467 - micro_f1: 0.9171 - val_loss: 0.5460 - val_micro_f1: 0.9276\n",
      "Epoch 17/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.5203 - micro_f1: 0.9241\n",
      "Epoch 00017: val_micro_f1 improved from 0.92763 to 0.93037, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 0.5224 - micro_f1: 0.9216 - val_loss: 0.5162 - val_micro_f1: 0.9304\n",
      "Epoch 18/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.5152 - micro_f1: 0.9222\n",
      "Epoch 00018: val_micro_f1 did not improve from 0.93037\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.5140 - micro_f1: 0.9221 - val_loss: 0.5254 - val_micro_f1: 0.9101\n",
      "Epoch 19/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.5071 - micro_f1: 0.9230\n",
      "Epoch 00019: val_micro_f1 improved from 0.93037 to 0.93366, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.5070 - micro_f1: 0.9231 - val_loss: 0.4823 - val_micro_f1: 0.9337\n",
      "Epoch 20/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.4983 - micro_f1: 0.9167\n",
      "Epoch 00020: val_micro_f1 did not improve from 0.93366\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.5055 - micro_f1: 0.9115 - val_loss: 0.4606 - val_micro_f1: 0.9298\n",
      "Epoch 21/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.4883 - micro_f1: 0.9219\n",
      "Epoch 00021: val_micro_f1 improved from 0.93366 to 0.94189, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 101ms/step - loss: 0.4845 - micro_f1: 0.9238 - val_loss: 0.4418 - val_micro_f1: 0.9419\n",
      "Epoch 22/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.4771 - micro_f1: 0.9271\n",
      "Epoch 00022: val_micro_f1 did not improve from 0.94189\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4734 - micro_f1: 0.9297 - val_loss: 0.4438 - val_micro_f1: 0.9337\n",
      "Epoch 23/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.4536 - micro_f1: 0.9360\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00023: val_micro_f1 did not improve from 0.94189\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4534 - micro_f1: 0.9366 - val_loss: 0.4304 - val_micro_f1: 0.9419\n",
      "Epoch 24/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.4409 - micro_f1: 0.9368\n",
      "Epoch 00024: val_micro_f1 did not improve from 0.94189\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4396 - micro_f1: 0.9363 - val_loss: 0.4163 - val_micro_f1: 0.9370\n",
      "Epoch 25/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.4326 - micro_f1: 0.9397\n",
      "Epoch 00025: val_micro_f1 improved from 0.94189 to 0.94737, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 0.4314 - micro_f1: 0.9401 - val_loss: 0.4059 - val_micro_f1: 0.9474\n",
      "Epoch 26/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.4194 - micro_f1: 0.9464\n",
      "Epoch 00026: val_micro_f1 improved from 0.94737 to 0.95066, saving model to BEST_MODEL_2.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_2.hdfs/assets\n",
      "44/44 [==============================] - 4s 101ms/step - loss: 0.4178 - micro_f1: 0.9482 - val_loss: 0.3966 - val_micro_f1: 0.9507\n",
      "Epoch 27/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.4191 - micro_f1: 0.9427\n",
      "Epoch 00027: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4159 - micro_f1: 0.9439 - val_loss: 0.3899 - val_micro_f1: 0.9424\n",
      "Epoch 28/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.4130 - micro_f1: 0.9433\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00028: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4134 - micro_f1: 0.9427 - val_loss: 0.3986 - val_micro_f1: 0.9337\n",
      "Epoch 29/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3976 - micro_f1: 0.9501\n",
      "Epoch 00029: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3994 - micro_f1: 0.9508 - val_loss: 0.3879 - val_micro_f1: 0.9435\n",
      "Epoch 30/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.4000 - micro_f1: 0.9571\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00030: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3987 - micro_f1: 0.9571 - val_loss: 0.3911 - val_micro_f1: 0.9419\n",
      "Epoch 31/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.3959 - micro_f1: 0.9489\n",
      "Epoch 00031: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3965 - micro_f1: 0.9491 - val_loss: 0.3818 - val_micro_f1: 0.9402\n",
      "Epoch 32/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3907 - micro_f1: 0.9506\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00032: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3917 - micro_f1: 0.9489 - val_loss: 0.3792 - val_micro_f1: 0.9435\n",
      "Epoch 33/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3837 - micro_f1: 0.9546\n",
      "Epoch 00033: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3866 - micro_f1: 0.9534 - val_loss: 0.3785 - val_micro_f1: 0.9435\n",
      "Epoch 34/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3921 - micro_f1: 0.9520\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00034: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3912 - micro_f1: 0.9531 - val_loss: 0.3783 - val_micro_f1: 0.9474\n",
      "Epoch 35/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3998 - micro_f1: 0.9477\n",
      "Epoch 00035: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3990 - micro_f1: 0.9489 - val_loss: 0.3780 - val_micro_f1: 0.9474\n",
      "Epoch 36/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3992 - micro_f1: 0.9528\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00036: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4005 - micro_f1: 0.9519 - val_loss: 0.3774 - val_micro_f1: 0.9452\n",
      "Epoch 37/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3817 - micro_f1: 0.9557\n",
      "Epoch 00037: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3816 - micro_f1: 0.9557 - val_loss: 0.3775 - val_micro_f1: 0.9452\n",
      "Epoch 38/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3814 - micro_f1: 0.9520\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00038: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3819 - micro_f1: 0.9522 - val_loss: 0.3775 - val_micro_f1: 0.9452\n",
      "Epoch 39/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3922 - micro_f1: 0.9516\n",
      "Epoch 00039: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3936 - micro_f1: 0.9505 - val_loss: 0.3773 - val_micro_f1: 0.9474\n",
      "Epoch 40/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3851 - micro_f1: 0.9506\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00040: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3862 - micro_f1: 0.9498 - val_loss: 0.3771 - val_micro_f1: 0.9435\n",
      "Epoch 41/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3804 - micro_f1: 0.9557\n",
      "Epoch 00041: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3804 - micro_f1: 0.9557 - val_loss: 0.3770 - val_micro_f1: 0.9435\n",
      "Epoch 42/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3780 - micro_f1: 0.9644\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 00042: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3763 - micro_f1: 0.9643 - val_loss: 0.3771 - val_micro_f1: 0.9435\n",
      "Epoch 43/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3868 - micro_f1: 0.9494\n",
      "Epoch 00043: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3843 - micro_f1: 0.9498 - val_loss: 0.3771 - val_micro_f1: 0.9474\n",
      "Epoch 44/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3854 - micro_f1: 0.9464\n",
      "Epoch 00044: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3878 - micro_f1: 0.9446 - val_loss: 0.3770 - val_micro_f1: 0.9452\n",
      "Epoch 45/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3858 - micro_f1: 0.9528\n",
      "Epoch 00045: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3875 - micro_f1: 0.9510 - val_loss: 0.3771 - val_micro_f1: 0.9452\n",
      "Epoch 46/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3818 - micro_f1: 0.9539\n",
      "Epoch 00046: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3820 - micro_f1: 0.9545 - val_loss: 0.3771 - val_micro_f1: 0.9435\n",
      "Epoch 47/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3896 - micro_f1: 0.9549\n",
      "Epoch 00047: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3888 - micro_f1: 0.9560 - val_loss: 0.3769 - val_micro_f1: 0.9435\n",
      "Epoch 48/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3838 - micro_f1: 0.9487\n",
      "Epoch 00048: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3822 - micro_f1: 0.9486 - val_loss: 0.3768 - val_micro_f1: 0.9435\n",
      "Epoch 49/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3854 - micro_f1: 0.9528\n",
      "Epoch 00049: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3875 - micro_f1: 0.9510 - val_loss: 0.3770 - val_micro_f1: 0.9435\n",
      "Epoch 50/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3962 - micro_f1: 0.9546\n",
      "Epoch 00050: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3943 - micro_f1: 0.9560 - val_loss: 0.3769 - val_micro_f1: 0.9435\n",
      "Epoch 51/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3849 - micro_f1: 0.9586\n",
      "Epoch 00051: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3834 - micro_f1: 0.9595 - val_loss: 0.3769 - val_micro_f1: 0.9435\n",
      "Epoch 52/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3816 - micro_f1: 0.9513\n",
      "Epoch 00052: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3822 - micro_f1: 0.9505 - val_loss: 0.3769 - val_micro_f1: 0.9452\n",
      "Epoch 53/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3955 - micro_f1: 0.9499\n",
      "Epoch 00053: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3956 - micro_f1: 0.9491 - val_loss: 0.3768 - val_micro_f1: 0.9435\n",
      "Epoch 54/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3932 - micro_f1: 0.9397\n",
      "Epoch 00054: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3905 - micro_f1: 0.9415 - val_loss: 0.3769 - val_micro_f1: 0.9435\n",
      "Epoch 55/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3748 - micro_f1: 0.9542\n",
      "Epoch 00055: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3763 - micro_f1: 0.9524 - val_loss: 0.3769 - val_micro_f1: 0.9457\n",
      "Epoch 56/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3772 - micro_f1: 0.9539\n",
      "Epoch 00056: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3804 - micro_f1: 0.9538 - val_loss: 0.3769 - val_micro_f1: 0.9452\n",
      "Epoch 57/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3923 - micro_f1: 0.9557\n",
      "Epoch 00057: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3911 - micro_f1: 0.9557 - val_loss: 0.3768 - val_micro_f1: 0.9435\n",
      "Epoch 58/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3855 - micro_f1: 0.9546\n",
      "Epoch 00058: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3867 - micro_f1: 0.9524 - val_loss: 0.3768 - val_micro_f1: 0.9457\n",
      "Epoch 59/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3829 - micro_f1: 0.9564\n",
      "Epoch 00059: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3864 - micro_f1: 0.9536 - val_loss: 0.3767 - val_micro_f1: 0.9457\n",
      "Epoch 60/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.3822 - micro_f1: 0.9527\n",
      "Epoch 00060: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3808 - micro_f1: 0.9536 - val_loss: 0.3767 - val_micro_f1: 0.9435\n",
      "Epoch 61/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3878 - micro_f1: 0.9528\n",
      "Epoch 00061: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3867 - micro_f1: 0.9529 - val_loss: 0.3768 - val_micro_f1: 0.9474\n",
      "Epoch 62/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3833 - micro_f1: 0.9549\n",
      "Epoch 00062: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3829 - micro_f1: 0.9550 - val_loss: 0.3766 - val_micro_f1: 0.9457\n",
      "Epoch 63/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3826 - micro_f1: 0.9557\n",
      "Epoch 00063: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3826 - micro_f1: 0.9548 - val_loss: 0.3767 - val_micro_f1: 0.9457\n",
      "Epoch 64/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.3786 - micro_f1: 0.9611\n",
      "Epoch 00064: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3832 - micro_f1: 0.9586 - val_loss: 0.3768 - val_micro_f1: 0.9474\n",
      "Epoch 65/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3914 - micro_f1: 0.9487\n",
      "Epoch 00065: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3923 - micro_f1: 0.9489 - val_loss: 0.3767 - val_micro_f1: 0.9457\n",
      "Epoch 66/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.3807 - micro_f1: 0.9550\n",
      "Epoch 00066: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3812 - micro_f1: 0.9553 - val_loss: 0.3767 - val_micro_f1: 0.9457\n",
      "Epoch 67/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3839 - micro_f1: 0.9499\n",
      "Epoch 00067: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3850 - micro_f1: 0.9482 - val_loss: 0.3767 - val_micro_f1: 0.9457\n",
      "Epoch 68/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.3853 - micro_f1: 0.9497\n",
      "Epoch 00068: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3847 - micro_f1: 0.9510 - val_loss: 0.3766 - val_micro_f1: 0.9435\n",
      "Epoch 69/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3950 - micro_f1: 0.9491\n",
      "Epoch 00069: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3935 - micro_f1: 0.9503 - val_loss: 0.3765 - val_micro_f1: 0.9435\n",
      "Epoch 70/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3944 - micro_f1: 0.9524\n",
      "Epoch 00070: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3966 - micro_f1: 0.9508 - val_loss: 0.3764 - val_micro_f1: 0.9435\n",
      "Epoch 71/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3817 - micro_f1: 0.9600\n",
      "Epoch 00071: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3812 - micro_f1: 0.9600 - val_loss: 0.3765 - val_micro_f1: 0.9435\n",
      "Epoch 72/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3852 - micro_f1: 0.9554\n",
      "Epoch 00072: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3834 - micro_f1: 0.9557 - val_loss: 0.3764 - val_micro_f1: 0.9435\n",
      "Epoch 73/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3890 - micro_f1: 0.9477\n",
      "Epoch 00073: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3908 - micro_f1: 0.9460 - val_loss: 0.3765 - val_micro_f1: 0.9457\n",
      "Epoch 74/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3773 - micro_f1: 0.9561\n",
      "Epoch 00074: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3759 - micro_f1: 0.9574 - val_loss: 0.3763 - val_micro_f1: 0.9457\n",
      "Epoch 75/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3811 - micro_f1: 0.9506\n",
      "Epoch 00075: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3822 - micro_f1: 0.9508 - val_loss: 0.3764 - val_micro_f1: 0.9435\n",
      "Epoch 76/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.3876 - micro_f1: 0.9527\n",
      "Epoch 00076: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3875 - micro_f1: 0.9529 - val_loss: 0.3763 - val_micro_f1: 0.9457\n",
      "Epoch 77/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3982 - micro_f1: 0.9462\n",
      "Epoch 00077: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3973 - micro_f1: 0.9474 - val_loss: 0.3762 - val_micro_f1: 0.9435\n",
      "Epoch 78/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3889 - micro_f1: 0.9513\n",
      "Epoch 00078: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3884 - micro_f1: 0.9505 - val_loss: 0.3762 - val_micro_f1: 0.9435\n",
      "Epoch 79/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3822 - micro_f1: 0.9578\n",
      "Epoch 00079: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3869 - micro_f1: 0.9531 - val_loss: 0.3764 - val_micro_f1: 0.9435\n",
      "Epoch 80/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3816 - micro_f1: 0.9535\n",
      "Epoch 00080: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3847 - micro_f1: 0.9527 - val_loss: 0.3764 - val_micro_f1: 0.9435\n",
      "Epoch 81/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3788 - micro_f1: 0.9549\n",
      "Epoch 00081: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3791 - micro_f1: 0.9550 - val_loss: 0.3764 - val_micro_f1: 0.9474\n",
      "Epoch 82/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3915 - micro_f1: 0.9535\n",
      "Epoch 00082: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3909 - micro_f1: 0.9536 - val_loss: 0.3764 - val_micro_f1: 0.9435\n",
      "Epoch 83/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3825 - micro_f1: 0.9513\n",
      "Epoch 00083: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3821 - micro_f1: 0.9524 - val_loss: 0.3763 - val_micro_f1: 0.9435\n",
      "Epoch 84/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3865 - micro_f1: 0.9564\n",
      "Epoch 00084: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3889 - micro_f1: 0.9545 - val_loss: 0.3763 - val_micro_f1: 0.9435\n",
      "Epoch 85/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3826 - micro_f1: 0.9571\n",
      "Epoch 00085: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3818 - micro_f1: 0.9571 - val_loss: 0.3763 - val_micro_f1: 0.9435\n",
      "Epoch 86/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3806 - micro_f1: 0.9578\n",
      "Epoch 00086: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3808 - micro_f1: 0.9579 - val_loss: 0.3764 - val_micro_f1: 0.9435\n",
      "Epoch 87/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3898 - micro_f1: 0.9583\n",
      "Epoch 00087: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3873 - micro_f1: 0.9593 - val_loss: 0.3762 - val_micro_f1: 0.9435\n",
      "Epoch 88/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3856 - micro_f1: 0.9535\n",
      "Epoch 00088: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3845 - micro_f1: 0.9545 - val_loss: 0.3763 - val_micro_f1: 0.9435\n",
      "Epoch 89/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3869 - micro_f1: 0.9561\n",
      "Epoch 00089: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3872 - micro_f1: 0.9557 - val_loss: 0.3763 - val_micro_f1: 0.9435\n",
      "Epoch 90/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3921 - micro_f1: 0.9571\n",
      "Epoch 00090: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3902 - micro_f1: 0.9581 - val_loss: 0.3762 - val_micro_f1: 0.9435\n",
      "Epoch 91/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 0.3887 - micro_f1: 0.9512\n",
      "Epoch 00091: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3867 - micro_f1: 0.9529 - val_loss: 0.3762 - val_micro_f1: 0.9435\n",
      "Epoch 92/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3831 - micro_f1: 0.9520\n",
      "Epoch 00092: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3817 - micro_f1: 0.9531 - val_loss: 0.3762 - val_micro_f1: 0.9435\n",
      "Epoch 93/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3758 - micro_f1: 0.9568\n",
      "Epoch 00093: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3794 - micro_f1: 0.9548 - val_loss: 0.3763 - val_micro_f1: 0.9435\n",
      "Epoch 94/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3840 - micro_f1: 0.9520\n",
      "Epoch 00094: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3849 - micro_f1: 0.9512 - val_loss: 0.3763 - val_micro_f1: 0.9435\n",
      "Epoch 95/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3840 - micro_f1: 0.9539\n",
      "Epoch 00095: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3880 - micro_f1: 0.9517 - val_loss: 0.3763 - val_micro_f1: 0.9435\n",
      "Epoch 96/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3930 - micro_f1: 0.9535\n",
      "Epoch 00096: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3924 - micro_f1: 0.9536 - val_loss: 0.3760 - val_micro_f1: 0.9435\n",
      "Epoch 97/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3794 - micro_f1: 0.9531\n",
      "Epoch 00097: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3841 - micro_f1: 0.9515 - val_loss: 0.3760 - val_micro_f1: 0.9435\n",
      "Epoch 98/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3768 - micro_f1: 0.9586\n",
      "Epoch 00098: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.3780 - micro_f1: 0.9586 - val_loss: 0.3761 - val_micro_f1: 0.9435\n",
      "Epoch 99/100\n",
      "42/44 [===========================>..] - ETA: 0s - loss: 0.3701 - micro_f1: 0.9606\n",
      "Epoch 00099: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.3730 - micro_f1: 0.9567 - val_loss: 0.3762 - val_micro_f1: 0.9435\n",
      "Epoch 100/100\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.3833 - micro_f1: 0.9535\n",
      "Epoch 00100: val_micro_f1 did not improve from 0.95066\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3828 - micro_f1: 0.9536 - val_loss: 0.3762 - val_micro_f1: 0.9435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a70cc2f28>"
      ]
     },
     "execution_count": 155,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "#callbacks=[lrschedule_1, checkpoint_1, tensorboard_callback]\n",
    "#validation_data=((X_test_pad_seq,X_test_mask), y_test)\n",
    "#X_train_spectrogram, X_train_mask, X_test_spectrogram, X_test_mask\n",
    "opt = Adam(0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=[micro_f1])\n",
    "model.fit(x=X_train_spectrogram, y=y_train, validation_data=(X_test_spectrogram, y_test), \\\n",
    "          epochs=100, verbose=True, callbacks=[lrschedule_1, checkpoint_1, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBEU6zDQeB8N"
   },
   "outputs": [],
   "source": [
    "!zip -r logs.zip logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "QAOxgaiAXcLe",
    "outputId": "56335783-8601-4a6f-f14d-b96621088812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3966 - micro_f1: 0.9507\n",
      "Best Micro F1 score model 2= 0.9506579041481018\n"
     ]
    }
   ],
   "source": [
    "best_model_2 = tf.keras.models.load_model('BEST_MODEL_2.hdfs', custom_objects={'f1_score_micro':f1_score_micro,'micro_f1':micro_f1})\n",
    "best_f1_model_2 = best_model_2.evaluate(X_test_spectrogram, y_test)[1]\n",
    "print(\"Best Micro F1 score model 2=\",best_f1_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSl8ZOXjaNqJ"
   },
   "source": [
    "# **3. Data Augmentation**  \n",
    "<pre>\n",
    "Till now we have done with 2000 samples only. It is very less data. We are giving the process of generating augmented data below.\n",
    "\n",
    "There are two types of augmentation:\n",
    "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
    "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR4JSEDgaNqK"
   },
   "outputs": [],
   "source": [
    "## generating augmented data. \n",
    "def generate_augmented_data(file_path):\n",
    "    augmented_data = []\n",
    "    samples = load_wav(file_path, get_duration=False)\n",
    "    for time_value in [0.7, 1, 1.3]:\n",
    "        for pitch_value in [-1, 0, 1]:\n",
    "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
    "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
    "            augmented_data.append(final_data)\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRdefb-SaNqS"
   },
   "outputs": [],
   "source": [
    "temp_path = df_audio.iloc[0].path\n",
    "aug_temp = generate_augmented_data(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kzdG3iS-aNqc",
    "outputId": "df782dfd-c8c0-4273-8490-9812e37599e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGfo3ZX-r6HX"
   },
   "outputs": [],
   "source": [
    "def augment_data(X_data, y_data):    # 'X_data' is the data with the paths of the recordings\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    for path, label in tqdm(zip(X_data, y_data)):\n",
    "        sample_aug = generate_augmented_data(path)\n",
    "        X_augmented.extend(sample_aug)\n",
    "        y_augmented.extend([label]*9)\n",
    "\n",
    "    return np.array(X_augmented), np.array(y_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWTCEaVMKNjB"
   },
   "source": [
    "### **3.1 Raw Data Augmentation**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "f78acd4f487a441c8df95e5676e366d5",
      "754ee104f3924bba861c865745bab31c",
      "b53dbad588144d60a9b4814baa6beadf",
      "4f35e03f769a437ab5af7427b353da30",
      "d73225e3835340e19d23aeb04e236a2c",
      "c6b66b57dee1432284403efc726c9695",
      "f5b1648d78d34a1ea86e03c1d2f4e9b7",
      "ee402e09cb084d588db7d9ea204ede13",
      "9752d761145f48f99550a3b3891866f9",
      "20e0771214ce43d48c1956541975ff15",
      "4aad82199c424733ab12b4d3a722af9e",
      "9181d8ad6d8748dfa3e91b6e221b7a02",
      "9f90dccdbcc84952b5bed25d8bfc91e3",
      "20920ce1cf714469bfaf3bc0d0dc5250",
      "308c7145de9a4a59bf71863ea06cb69a",
      "0162b6b058934c09aad8f1a6bc33b2e4"
     ]
    },
    "id": "BHqD-9Fmupkf",
    "outputId": "2285b1ff-aed0-4c8f-d02c-74b4b5a17fa0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78acd4f487a441c8df95e5676e366d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9752d761145f48f99550a3b3891866f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# X_train_augmented, y_train_augmented = augment_data(X_train, y_train)\n",
    "# X_test_augmented, y_test_augmented = augment_data(X_test, y_test)\n",
    "\n",
    "# # Saving the pickels\n",
    "# # ------------------\n",
    "# pkl_path = \"/content/drive/My Drive/Colab Notebooks/Spoken Digit Recognition/Raw augmented pickles/\"\n",
    "# np.save(pkl_path+'X_train_augmented', X_train_augmented)\n",
    "# np.save(pkl_path+'y_train_augmented', y_train_augmented)\n",
    "# np.save(pkl_path+'X_test_augmented', X_test_augmented)\n",
    "# np.save(pkl_path+'y_test_augmented', y_test_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGbTH1mDVeUl"
   },
   "outputs": [],
   "source": [
    "## Loading the pickels\n",
    "## -------------------\n",
    "pkl_path = \"/content/drive/My Drive/Colab Notebooks/Spoken Digit Recognition/Raw augmented pickles/\"\n",
    "X_train_augmented = np.load(pkl_path+'X_train_augmented.npy', allow_pickle=True)\n",
    "y_train_augmented = np.load(pkl_path+'y_train_augmented.npy', allow_pickle=True)\n",
    "X_test_augmented = np.load(pkl_path+'X_test_augmented.npy', allow_pickle=True)\n",
    "y_test_augmented = np.load(pkl_path+'y_test_augmented.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "Tm1vFMuoEPCe",
    "outputId": "585e7fb0-0160-44c1-ee80-048a22adfe13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12600\n",
      "12600\n",
      "5400\n",
      "5400\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_augmented))\n",
    "print(len(y_train_augmented))\n",
    "print(len(X_test_augmented))\n",
    "print(len(y_test_augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COqRF_ydvVnK"
   },
   "outputs": [],
   "source": [
    "# max_length = 17640\n",
    "X_train_padded_aug = pad_sequence(X_train_augmented, max_length)\n",
    "X_test_padded_aug = pad_sequence(X_test_augmented, max_length)\n",
    "\n",
    "X_train_mask_aug = mask_padded_sequence(X_train_padded_aug)\n",
    "X_test_mask_aug = mask_padded_sequence(X_test_padded_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZckytZsraNqk"
   },
   "source": [
    "As discussed above, for one data point, we will get 9 augmented data points.  \n",
    "We have 2000 data points(train plus test) so, after augmentation we will get 18000 ( train - 12600, test - 5400). \n",
    "\n",
    "do the above steps i.e training with raw data and spectrogram data with augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "rEdNQk0Tt_s-",
    "outputId": "d16c8b86-86ce-4f12-bb47-de3d8a3ef6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12600, 17640)\n",
      "(12600, 17640)\n",
      "(5400, 17640)\n",
      "(5400, 17640)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_padded_aug.shape)\n",
    "print(X_train_mask_aug.shape)\n",
    "print(X_test_padded_aug.shape)\n",
    "print(X_test_mask_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ao8IcfCdv6O4"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_X = Input(shape=(max_length,1))\n",
    "input_mask = Input(shape=max_length, dtype='bool')\n",
    "lstm = LSTM(units=64)(inputs=input_X, mask=input_mask)\n",
    "dense = Dense(units=32, activation='relu')(lstm)\n",
    "dense = BatchNormalization()(dense)\n",
    "output = Dense(units=10, activation='softmax', name=\"Output\")(dense)\n",
    "\n",
    "model = Model(inputs=[input_X,input_mask], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "FnrK3T2exvGi",
    "outputId": "2e490f7e-2b2b-4251-b795-a36bd1524963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 17640, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 17640)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           16896       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           2080        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Output (Dense)                  (None, 10)           330         batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 19,434\n",
      "Trainable params: 19,370\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKhdQAYUx3T9"
   },
   "outputs": [],
   "source": [
    "# For more info on ModelCheckpoint, refer https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_path = \"BEST_MODEL_3.hdfs\"\n",
    "checkpoint_1 = ModelCheckpoint(filepath=model_path, monitor='val_micro_f1',verbose=1, mode='max', save_best_only=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# https://stackoverflow.com/a/42963385/7697658\n",
    "lrschedule_1 = ReduceLROnPlateau(monitor='val_micro_f1', patience=2, mode='max', verbose=1, factor=0.50)\n",
    "\n",
    "import datetime\n",
    "log_dir=\"logs/3/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=True)\n",
    "\n",
    "def f1_score_micro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average = 'micro')\n",
    "    \n",
    "def micro_f1(y_true, y_proba):\n",
    "    y_pred = tf.math.argmax(y_proba,axis=1)\n",
    "    return tf.py_function(f1_score_micro, (y_true,y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSGvhIDnyFhW"
   },
   "outputs": [],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "AdKXVRlpaNql",
    "outputId": "aa0d681a-bc0d-4b59-fb35-478d4220ff56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/394 [..............................] - ETA: 14:13 - loss: 2.3013 - micro_f1: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 1.0198s vs `on_train_batch_end` time: 3.3347s). Check your callbacks.\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3033 - micro_f1: 0.1003\n",
      "Epoch 00001: val_micro_f1 improved from -inf to 0.10022, saving model to BEST_MODEL_3.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_3.hdfs/assets\n",
      "394/394 [==============================] - 349s 885ms/step - loss: 2.3033 - micro_f1: 0.1003 - val_loss: 2.3042 - val_micro_f1: 0.1002\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3031 - micro_f1: 0.1030\n",
      "Epoch 00002: val_micro_f1 did not improve from 0.10022\n",
      "394/394 [==============================] - 335s 851ms/step - loss: 2.3031 - micro_f1: 0.1030 - val_loss: 2.3190 - val_micro_f1: 0.0999\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3030 - micro_f1: 0.1022\n",
      "Epoch 00003: val_micro_f1 improved from 0.10022 to 0.10041, saving model to BEST_MODEL_3.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_3.hdfs/assets\n",
      "394/394 [==============================] - 347s 881ms/step - loss: 2.3030 - micro_f1: 0.1022 - val_loss: 6.2611 - val_micro_f1: 0.1004\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3031 - micro_f1: 0.0991\n",
      "Epoch 00004: val_micro_f1 did not improve from 0.10041\n",
      "394/394 [==============================] - 342s 867ms/step - loss: 2.3031 - micro_f1: 0.0991 - val_loss: 7.7177 - val_micro_f1: 0.0999\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3031 - micro_f1: 0.0972\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00005: val_micro_f1 did not improve from 0.10041\n",
      "394/394 [==============================] - 341s 866ms/step - loss: 2.3031 - micro_f1: 0.0972 - val_loss: 2.3869 - val_micro_f1: 0.1004\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3025 - micro_f1: 0.0972\n",
      "Epoch 00006: val_micro_f1 did not improve from 0.10041\n",
      "394/394 [==============================] - 339s 860ms/step - loss: 2.3025 - micro_f1: 0.0972 - val_loss: 3.3563 - val_micro_f1: 0.0991\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3026 - micro_f1: 0.1001\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00007: val_micro_f1 did not improve from 0.10041\n",
      "394/394 [==============================] - 331s 840ms/step - loss: 2.3026 - micro_f1: 0.1001 - val_loss: 3.0269 - val_micro_f1: 0.1004\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3022 - micro_f1: 0.1104\n",
      "Epoch 00008: val_micro_f1 did not improve from 0.10041\n",
      "394/394 [==============================] - 318s 807ms/step - loss: 2.3022 - micro_f1: 0.1104 - val_loss: 2.3521 - val_micro_f1: 0.0973\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3022 - micro_f1: 0.1037\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00009: val_micro_f1 did not improve from 0.10041\n",
      "394/394 [==============================] - 316s 801ms/step - loss: 2.3022 - micro_f1: 0.1037 - val_loss: 3.6968 - val_micro_f1: 0.0999\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - ETA: 0s - loss: 2.3021 - micro_f1: 0.1106\n",
      "Epoch 00010: val_micro_f1 did not improve from 0.10041\n",
      "394/394 [==============================] - 314s 797ms/step - loss: 2.3021 - micro_f1: 0.1106 - val_loss: 3.5233 - val_micro_f1: 0.0939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a81bf9ef0>"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "\n",
    "opt = Adam(0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=[micro_f1])\n",
    "model.fit(x=[X_train_padded_aug,X_train_mask_aug], y=y_train_augmented, validation_data=([X_test_padded_aug,X_test_mask_aug], y_test_augmented), \\\n",
    "          epochs=10, verbose=True, callbacks=[lrschedule_1, checkpoint_1, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "KzWsQu43ZWLe",
    "outputId": "fd32d523-5965-410d-9616-efb13c58027d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 52s 306ms/step - loss: 6.2611 - micro_f1: 0.1004\n",
      "Best Micro F1 score model 3= 0.10040680319070816\n"
     ]
    }
   ],
   "source": [
    "best_model_3 = tf.keras.models.load_model('BEST_MODEL_3.hdfs', custom_objects={'f1_score_micro':f1_score_micro,'micro_f1':micro_f1})\n",
    "best_f1_model_3 = best_model_3.evaluate([X_test_padded_aug,X_test_mask_aug], y_test_augmented)[1]\n",
    "print(\"Best Micro F1 score model 3=\", best_f1_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRq7flGAKTS1"
   },
   "source": [
    "### **3.2 Spectogram Data Augmentation**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEHp_0Lz8dRz"
   },
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(raw_data):\n",
    "    '''converting to spectrogram'''\n",
    "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
    "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
    "    return logmel_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HX_HvWy9_Wib"
   },
   "outputs": [],
   "source": [
    "## generating augmented data. \n",
    "def generate_augmented_data(file_path):\n",
    "    augmented_data = []\n",
    "    samples = load_wav(file_path, get_duration=False)\n",
    "    for time_value in [0.7, 1, 1.3]:\n",
    "        for pitch_value in [-1, 0, 1]:\n",
    "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
    "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
    "            augmented_data.append(final_data)\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQlRvQth_Wiy"
   },
   "outputs": [],
   "source": [
    "def augment_data(X_data, y_data):    # 'X_data' is the data with the paths of the recordings\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    for path, label in tqdm(zip(X_data, y_data)):\n",
    "        sample_aug = generate_augmented_data(path)\n",
    "        X_augmented.extend(sample_aug)\n",
    "        y_augmented.extend([label]*9)\n",
    "\n",
    "    return np.array(X_augmented), np.array(y_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213,
     "referenced_widgets": [
      "43bc91939ea2410db48b78e993dbdb69",
      "9f579ab2ebfc42109b9c3e6ed14368aa",
      "0869af9fb4c84379a87340845cfaa244",
      "b9d4f8d79e4944db9830d460fc06a74f",
      "031ecba5576d4a97a1e08db7ac648c6a",
      "b4cae1fe1c1d44ecba6b70cdcbd7c072",
      "21f9a7b24f324dabacc5bdd2dd2aa951",
      "0d5a84aad0f64c7eadf7f79386eca78e",
      "ad9bf13f0bdf4e4a84da72d728671189",
      "7c88c3a1a4274107aa3ab74d0e7c9ed0",
      "3fd96e3889914e7b85747acf583b7707",
      "15dceace35794ea481136f3190fc9d23",
      "4aec3b6322fb4420bb16e2ba15130e44",
      "0ee435d4708540f19aa66cf46338c4a4",
      "ecb0d59941ff45b5afa83681c14e45d5",
      "e7cbc4fda21c4031a80789417099fbaf",
      "fe6a57c7ecd64948a5c51d342b291c89",
      "725f60dec5f04bf0a65ddab5293cb6fd",
      "8229cf19c28348bd92315628a6e6796c",
      "4cb7a749fdc14d158016ca6a06809cf8",
      "ec2a993df3214831be3e35882f4f0faf",
      "240eaf674b75467dafcf3f56f7d316aa",
      "81eb5de39fbc4682a1e3eb2ea718faab",
      "6bd00b4728f04843855805d3a0209fe6",
      "14146a9d152d47b68fa65271249a5873",
      "94822acdae644145a1695e259cca3a68",
      "d88c9980d46748f982799bb1e70cb80e",
      "a6ac3d4d86df4fe68a72e88944958932",
      "b43e41140732486aa02953c65d757eb8",
      "a7a22410247942899f7d253fa81aa6cc",
      "9ed01f09e4924d4897de2c8e2aa35e07",
      "98063d8d4a574fada648d8c56d8cab88"
     ]
    },
    "id": "rdUjNOnbKXtC",
    "outputId": "20ef10c7-abff-4eaa-e400-d2c206b4eca2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bc91939ea2410db48b78e993dbdb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9bf13f0bdf4e4a84da72d728671189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6a57c7ecd64948a5c51d342b291c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12600.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14146a9d152d47b68fa65271249a5873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5400.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)\n",
    "X_test_augmented, y_test_augmented = augment_data(X_test, y_test)\n",
    "\n",
    "X_train_pad_seq = pad_sequence(X_train_augmented, max_length)\n",
    "X_test_pad_seq = pad_sequence(X_test_augmented, max_length)\n",
    "\n",
    "X_train_spectrogram = get_spectogram_data(X_train_pad_seq)\n",
    "X_test_spectrogram = get_spectogram_data(X_test_pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "K7Lxu71zOCRt",
    "outputId": "2b69722a-fb94-46d6-9d74-63c5485da832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 128)\n",
      "(None, 1, 64, 128)\n",
      "(None, 1, 128, 64)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_X = Input(shape=(64,35), name=\"Input_X\")\n",
    "lstm = LSTM(units=128, return_sequences=True)(inputs=input_X)\n",
    "print(lstm.shape)\n",
    "lstm = tf.expand_dims(lstm, axis=1)\n",
    "print(lstm.shape)\n",
    "lstm = tf.transpose(lstm, perm=[0,1,3,2])\n",
    "print(lstm.shape)\n",
    "avg_timesteps = GlobalAveragePooling2D()(lstm)\n",
    "print(avg_timesteps.shape)\n",
    "avg_timesteps = BatchNormalization()(avg_timesteps)\n",
    "dense = Dense(units=64, activation='relu', kernel_initializer=initializers.GlorotUniform(seed=0), kernel_regularizer=regularizers.l2())(avg_timesteps)\n",
    "output = Dense(units=10, activation='softmax', name=\"Output\")(dense)\n",
    "\n",
    "model = Model(inputs=input_X, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "bOklcdbJOCR6",
    "outputId": "8e6ec646-f464-4d2f-fb42-c273da2e9be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_X (InputLayer)         [(None, 64, 35)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64, 128)           83968     \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 1, 64, 128)]      0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Transpose (Tenso [(None, 1, 128, 64)]      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 89,034\n",
      "Trainable params: 88,906\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SZbWfKHbOCSA",
    "outputId": "d6967860-b9d1-4621-b047-b1eca86bcd55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "# For more info on ModelCheckpoint, refer https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_path = \"BEST_MODEL_4.hdfs\"\n",
    "checkpoint_1 = ModelCheckpoint(filepath=model_path, monitor='val_micro_f1',verbose=1, mode='max', save_best_only=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# https://stackoverflow.com/a/42963385/7697658\n",
    "lrschedule_1 = ReduceLROnPlateau(monitor='val_micro_f1', min_lr=0.000001, patience=2, mode='max', verbose=1, factor=0.50)\n",
    "\n",
    "import datetime\n",
    "log_dir=\"logs/4/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=True)\n",
    "\n",
    "def f1_score_micro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average = 'micro')\n",
    "    \n",
    "def micro_f1(y_true, y_proba):\n",
    "    y_pred = tf.math.argmax(y_proba,axis=1)\n",
    "    return tf.py_function(f1_score_micro, (y_true,y_pred), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4Mt7UScOCSF"
   },
   "outputs": [],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jNeMZ3NhOCSM",
    "outputId": "38f79912-769a-4af6-f5f3-d2e2180ef252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "  2/394 [..............................] - ETA: 26s - loss: 3.0322 - micro_f1: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0178s vs `on_train_batch_end` time: 0.1202s). Check your callbacks.\n",
      "390/394 [============================>.] - ETA: 0s - loss: 1.5729 - micro_f1: 0.5885\n",
      "Epoch 00001: val_micro_f1 improved from -inf to 0.36089, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 10s 26ms/step - loss: 1.5680 - micro_f1: 0.5898 - val_loss: 2.0028 - val_micro_f1: 0.3609\n",
      "Epoch 2/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.8200 - micro_f1: 0.7946\n",
      "Epoch 00002: val_micro_f1 improved from 0.36089 to 0.62130, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.8190 - micro_f1: 0.7951 - val_loss: 1.0985 - val_micro_f1: 0.6213\n",
      "Epoch 3/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.6993 - micro_f1: 0.8183\n",
      "Epoch 00003: val_micro_f1 improved from 0.62130 to 0.74581, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.6993 - micro_f1: 0.8183 - val_loss: 0.8089 - val_micro_f1: 0.7458\n",
      "Epoch 4/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.6298 - micro_f1: 0.8332\n",
      "Epoch 00004: val_micro_f1 improved from 0.74581 to 0.74883, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 10s 24ms/step - loss: 0.6295 - micro_f1: 0.8337 - val_loss: 0.7803 - val_micro_f1: 0.7488\n",
      "Epoch 5/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.5889 - micro_f1: 0.8491\n",
      "Epoch 00005: val_micro_f1 improved from 0.74883 to 0.74926, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.5893 - micro_f1: 0.8487 - val_loss: 0.7945 - val_micro_f1: 0.7493\n",
      "Epoch 6/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.5593 - micro_f1: 0.8565\n",
      "Epoch 00006: val_micro_f1 improved from 0.74926 to 0.84455, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.5603 - micro_f1: 0.8561 - val_loss: 0.5606 - val_micro_f1: 0.8446\n",
      "Epoch 7/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.5425 - micro_f1: 0.8614\n",
      "Epoch 00007: val_micro_f1 improved from 0.84455 to 0.85682, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 10s 24ms/step - loss: 0.5425 - micro_f1: 0.8614 - val_loss: 0.5047 - val_micro_f1: 0.8568\n",
      "Epoch 8/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.4862 - micro_f1: 0.8776\n",
      "Epoch 00008: val_micro_f1 improved from 0.85682 to 0.88918, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.4861 - micro_f1: 0.8776 - val_loss: 0.4343 - val_micro_f1: 0.8892\n",
      "Epoch 9/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.4638 - micro_f1: 0.8853\n",
      "Epoch 00009: val_micro_f1 did not improve from 0.88918\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.4637 - micro_f1: 0.8855 - val_loss: 0.4948 - val_micro_f1: 0.8581\n",
      "Epoch 10/80\n",
      "389/394 [============================>.] - ETA: 0s - loss: 0.4613 - micro_f1: 0.8838\n",
      "Epoch 00010: val_micro_f1 improved from 0.88918 to 0.90280, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.4611 - micro_f1: 0.8839 - val_loss: 0.4070 - val_micro_f1: 0.9028\n",
      "Epoch 11/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.4219 - micro_f1: 0.8958\n",
      "Epoch 00011: val_micro_f1 did not improve from 0.90280\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.4219 - micro_f1: 0.8958 - val_loss: 0.3957 - val_micro_f1: 0.9010\n",
      "Epoch 12/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.4064 - micro_f1: 0.8997\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00012: val_micro_f1 did not improve from 0.90280\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.4064 - micro_f1: 0.8997 - val_loss: 0.4148 - val_micro_f1: 0.8951\n",
      "Epoch 13/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.3674 - micro_f1: 0.9177\n",
      "Epoch 00013: val_micro_f1 improved from 0.90280 to 0.91870, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 10s 25ms/step - loss: 0.3671 - micro_f1: 0.9180 - val_loss: 0.3579 - val_micro_f1: 0.9187\n",
      "Epoch 14/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.3511 - micro_f1: 0.9212\n",
      "Epoch 00014: val_micro_f1 improved from 0.91870 to 0.92480, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.3507 - micro_f1: 0.9215 - val_loss: 0.3408 - val_micro_f1: 0.9248\n",
      "Epoch 15/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.3396 - micro_f1: 0.9246\n",
      "Epoch 00015: val_micro_f1 did not improve from 0.92480\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.3396 - micro_f1: 0.9246 - val_loss: 0.3548 - val_micro_f1: 0.9104\n",
      "Epoch 16/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.3265 - micro_f1: 0.9270\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00016: val_micro_f1 did not improve from 0.92480\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.3267 - micro_f1: 0.9268 - val_loss: 0.3288 - val_micro_f1: 0.9237\n",
      "Epoch 17/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.3020 - micro_f1: 0.9391\n",
      "Epoch 00017: val_micro_f1 improved from 0.92480 to 0.93090, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.3023 - micro_f1: 0.9391 - val_loss: 0.3116 - val_micro_f1: 0.9309\n",
      "Epoch 18/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2960 - micro_f1: 0.9369\n",
      "Epoch 00018: val_micro_f1 did not improve from 0.93090\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2960 - micro_f1: 0.9369 - val_loss: 0.3093 - val_micro_f1: 0.9306\n",
      "Epoch 19/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.2871 - micro_f1: 0.9406\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00019: val_micro_f1 did not improve from 0.93090\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2873 - micro_f1: 0.9406 - val_loss: 0.3050 - val_micro_f1: 0.9292\n",
      "Epoch 20/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2779 - micro_f1: 0.9437\n",
      "Epoch 00020: val_micro_f1 improved from 0.93090 to 0.93503, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 10s 25ms/step - loss: 0.2780 - micro_f1: 0.9438 - val_loss: 0.2909 - val_micro_f1: 0.9350\n",
      "Epoch 21/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.2775 - micro_f1: 0.9437\n",
      "Epoch 00021: val_micro_f1 did not improve from 0.93503\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2770 - micro_f1: 0.9441 - val_loss: 0.2922 - val_micro_f1: 0.9333\n",
      "Epoch 22/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2703 - micro_f1: 0.9451\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00022: val_micro_f1 did not improve from 0.93503\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2702 - micro_f1: 0.9451 - val_loss: 0.2949 - val_micro_f1: 0.9323\n",
      "Epoch 23/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2652 - micro_f1: 0.9469\n",
      "Epoch 00023: val_micro_f1 improved from 0.93503 to 0.93540, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.2661 - micro_f1: 0.9464 - val_loss: 0.2876 - val_micro_f1: 0.9354\n",
      "Epoch 24/80\n",
      "389/394 [============================>.] - ETA: 0s - loss: 0.2593 - micro_f1: 0.9492\n",
      "Epoch 00024: val_micro_f1 improved from 0.93540 to 0.93923, saving model to BEST_MODEL_4.hdfs\n",
      "INFO:tensorflow:Assets written to: BEST_MODEL_4.hdfs/assets\n",
      "394/394 [==============================] - 9s 22ms/step - loss: 0.2589 - micro_f1: 0.9495 - val_loss: 0.2828 - val_micro_f1: 0.9392\n",
      "Epoch 25/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2626 - micro_f1: 0.9482\n",
      "Epoch 00025: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2625 - micro_f1: 0.9483 - val_loss: 0.2865 - val_micro_f1: 0.9352\n",
      "Epoch 26/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2553 - micro_f1: 0.9506\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00026: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2553 - micro_f1: 0.9506 - val_loss: 0.2823 - val_micro_f1: 0.9372\n",
      "Epoch 27/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2574 - micro_f1: 0.9513\n",
      "Epoch 00027: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2575 - micro_f1: 0.9512 - val_loss: 0.2820 - val_micro_f1: 0.9361\n",
      "Epoch 28/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2582 - micro_f1: 0.9500\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00028: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2581 - micro_f1: 0.9502 - val_loss: 0.2815 - val_micro_f1: 0.9370\n",
      "Epoch 29/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2531 - micro_f1: 0.9523\n",
      "Epoch 00029: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2530 - micro_f1: 0.9524 - val_loss: 0.2814 - val_micro_f1: 0.9359\n",
      "Epoch 30/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2518 - micro_f1: 0.9522\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00030: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2516 - micro_f1: 0.9524 - val_loss: 0.2822 - val_micro_f1: 0.9355\n",
      "Epoch 31/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2499 - micro_f1: 0.9527\n",
      "Epoch 00031: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2498 - micro_f1: 0.9526 - val_loss: 0.2804 - val_micro_f1: 0.9357\n",
      "Epoch 32/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2543 - micro_f1: 0.9526\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00032: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2544 - micro_f1: 0.9526 - val_loss: 0.2801 - val_micro_f1: 0.9368\n",
      "Epoch 33/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2524 - micro_f1: 0.9548\n",
      "Epoch 00033: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2526 - micro_f1: 0.9549 - val_loss: 0.2798 - val_micro_f1: 0.9359\n",
      "Epoch 34/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2508 - micro_f1: 0.9552\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00034: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2509 - micro_f1: 0.9551 - val_loss: 0.2802 - val_micro_f1: 0.9365\n",
      "Epoch 35/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2458 - micro_f1: 0.9552\n",
      "Epoch 00035: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2458 - micro_f1: 0.9552 - val_loss: 0.2808 - val_micro_f1: 0.9368\n",
      "Epoch 36/80\n",
      "389/394 [============================>.] - ETA: 0s - loss: 0.2475 - micro_f1: 0.9535\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 00036: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2482 - micro_f1: 0.9532 - val_loss: 0.2799 - val_micro_f1: 0.9366\n",
      "Epoch 37/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2475 - micro_f1: 0.9555\n",
      "Epoch 00037: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2474 - micro_f1: 0.9553 - val_loss: 0.2807 - val_micro_f1: 0.9351\n",
      "Epoch 38/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2494 - micro_f1: 0.9534\n",
      "Epoch 00038: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2495 - micro_f1: 0.9532 - val_loss: 0.2801 - val_micro_f1: 0.9355\n",
      "Epoch 39/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2474 - micro_f1: 0.9552\n",
      "Epoch 00039: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2477 - micro_f1: 0.9551 - val_loss: 0.2797 - val_micro_f1: 0.9357\n",
      "Epoch 40/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2511 - micro_f1: 0.9523\n",
      "Epoch 00040: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2511 - micro_f1: 0.9523 - val_loss: 0.2806 - val_micro_f1: 0.9360\n",
      "Epoch 41/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2520 - micro_f1: 0.9527\n",
      "Epoch 00041: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2521 - micro_f1: 0.9524 - val_loss: 0.2802 - val_micro_f1: 0.9360\n",
      "Epoch 42/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2452 - micro_f1: 0.9550\n",
      "Epoch 00042: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2453 - micro_f1: 0.9549 - val_loss: 0.2802 - val_micro_f1: 0.9361\n",
      "Epoch 43/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2520 - micro_f1: 0.9533\n",
      "Epoch 00043: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2518 - micro_f1: 0.9535 - val_loss: 0.2809 - val_micro_f1: 0.9365\n",
      "Epoch 44/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2430 - micro_f1: 0.9572\n",
      "Epoch 00044: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2430 - micro_f1: 0.9572 - val_loss: 0.2802 - val_micro_f1: 0.9360\n",
      "Epoch 45/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2490 - micro_f1: 0.9547\n",
      "Epoch 00045: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2490 - micro_f1: 0.9549 - val_loss: 0.2803 - val_micro_f1: 0.9364\n",
      "Epoch 46/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.2493 - micro_f1: 0.9531\n",
      "Epoch 00046: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2506 - micro_f1: 0.9524 - val_loss: 0.2799 - val_micro_f1: 0.9360\n",
      "Epoch 47/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.2509 - micro_f1: 0.9534\n",
      "Epoch 00047: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2501 - micro_f1: 0.9538 - val_loss: 0.2806 - val_micro_f1: 0.9368\n",
      "Epoch 48/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2504 - micro_f1: 0.9544\n",
      "Epoch 00048: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2504 - micro_f1: 0.9544 - val_loss: 0.2801 - val_micro_f1: 0.9359\n",
      "Epoch 49/80\n",
      "389/394 [============================>.] - ETA: 0s - loss: 0.2444 - micro_f1: 0.9553\n",
      "Epoch 00049: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2447 - micro_f1: 0.9552 - val_loss: 0.2798 - val_micro_f1: 0.9362\n",
      "Epoch 50/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2451 - micro_f1: 0.9559\n",
      "Epoch 00050: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2451 - micro_f1: 0.9558 - val_loss: 0.2796 - val_micro_f1: 0.9359\n",
      "Epoch 51/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2416 - micro_f1: 0.9579\n",
      "Epoch 00051: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2413 - micro_f1: 0.9580 - val_loss: 0.2797 - val_micro_f1: 0.9359\n",
      "Epoch 52/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2461 - micro_f1: 0.9555\n",
      "Epoch 00052: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2461 - micro_f1: 0.9555 - val_loss: 0.2805 - val_micro_f1: 0.9365\n",
      "Epoch 53/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2491 - micro_f1: 0.9531\n",
      "Epoch 00053: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2491 - micro_f1: 0.9531 - val_loss: 0.2804 - val_micro_f1: 0.9364\n",
      "Epoch 54/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2526 - micro_f1: 0.9510\n",
      "Epoch 00054: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 0.2524 - micro_f1: 0.9509 - val_loss: 0.2797 - val_micro_f1: 0.9361\n",
      "Epoch 55/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2477 - micro_f1: 0.9536\n",
      "Epoch 00055: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2473 - micro_f1: 0.9538 - val_loss: 0.2795 - val_micro_f1: 0.9353\n",
      "Epoch 56/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2488 - micro_f1: 0.9534\n",
      "Epoch 00056: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2489 - micro_f1: 0.9534 - val_loss: 0.2800 - val_micro_f1: 0.9359\n",
      "Epoch 57/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2505 - micro_f1: 0.9535\n",
      "Epoch 00057: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2504 - micro_f1: 0.9536 - val_loss: 0.2792 - val_micro_f1: 0.9363\n",
      "Epoch 58/80\n",
      "389/394 [============================>.] - ETA: 0s - loss: 0.2487 - micro_f1: 0.9552\n",
      "Epoch 00058: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2488 - micro_f1: 0.9549 - val_loss: 0.2799 - val_micro_f1: 0.9372\n",
      "Epoch 59/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.2468 - micro_f1: 0.9569\n",
      "Epoch 00059: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2464 - micro_f1: 0.9571 - val_loss: 0.2799 - val_micro_f1: 0.9355\n",
      "Epoch 60/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2480 - micro_f1: 0.9526\n",
      "Epoch 00060: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2476 - micro_f1: 0.9528 - val_loss: 0.2798 - val_micro_f1: 0.9368\n",
      "Epoch 61/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2502 - micro_f1: 0.9525\n",
      "Epoch 00061: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2502 - micro_f1: 0.9525 - val_loss: 0.2794 - val_micro_f1: 0.9362\n",
      "Epoch 62/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.2526 - micro_f1: 0.9518\n",
      "Epoch 00062: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2520 - micro_f1: 0.9521 - val_loss: 0.2800 - val_micro_f1: 0.9364\n",
      "Epoch 63/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2509 - micro_f1: 0.9515\n",
      "Epoch 00063: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2509 - micro_f1: 0.9515 - val_loss: 0.2796 - val_micro_f1: 0.9370\n",
      "Epoch 64/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2468 - micro_f1: 0.9550\n",
      "Epoch 00064: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2468 - micro_f1: 0.9550 - val_loss: 0.2798 - val_micro_f1: 0.9368\n",
      "Epoch 65/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2492 - micro_f1: 0.9522\n",
      "Epoch 00065: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2494 - micro_f1: 0.9520 - val_loss: 0.2802 - val_micro_f1: 0.9366\n",
      "Epoch 66/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2456 - micro_f1: 0.9551\n",
      "Epoch 00066: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2456 - micro_f1: 0.9549 - val_loss: 0.2797 - val_micro_f1: 0.9374\n",
      "Epoch 67/80\n",
      "393/394 [============================>.] - ETA: 0s - loss: 0.2480 - micro_f1: 0.9571\n",
      "Epoch 00067: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2480 - micro_f1: 0.9571 - val_loss: 0.2798 - val_micro_f1: 0.9366\n",
      "Epoch 68/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2505 - micro_f1: 0.9534\n",
      "Epoch 00068: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2505 - micro_f1: 0.9534 - val_loss: 0.2796 - val_micro_f1: 0.9371\n",
      "Epoch 69/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2484 - micro_f1: 0.9548\n",
      "Epoch 00069: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2483 - micro_f1: 0.9547 - val_loss: 0.2798 - val_micro_f1: 0.9368\n",
      "Epoch 70/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2495 - micro_f1: 0.9542\n",
      "Epoch 00070: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2494 - micro_f1: 0.9542 - val_loss: 0.2790 - val_micro_f1: 0.9363\n",
      "Epoch 71/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2453 - micro_f1: 0.9559\n",
      "Epoch 00071: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2452 - micro_f1: 0.9560 - val_loss: 0.2796 - val_micro_f1: 0.9368\n",
      "Epoch 72/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.2501 - micro_f1: 0.9526\n",
      "Epoch 00072: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2502 - micro_f1: 0.9527 - val_loss: 0.2797 - val_micro_f1: 0.9366\n",
      "Epoch 73/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2456 - micro_f1: 0.9551\n",
      "Epoch 00073: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2454 - micro_f1: 0.9553 - val_loss: 0.2794 - val_micro_f1: 0.9364\n",
      "Epoch 74/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2454 - micro_f1: 0.9543\n",
      "Epoch 00074: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2454 - micro_f1: 0.9541 - val_loss: 0.2791 - val_micro_f1: 0.9366\n",
      "Epoch 75/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2483 - micro_f1: 0.9541\n",
      "Epoch 00075: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2483 - micro_f1: 0.9541 - val_loss: 0.2796 - val_micro_f1: 0.9368\n",
      "Epoch 76/80\n",
      "394/394 [==============================] - ETA: 0s - loss: 0.2501 - micro_f1: 0.9524\n",
      "Epoch 00076: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2501 - micro_f1: 0.9524 - val_loss: 0.2797 - val_micro_f1: 0.9370\n",
      "Epoch 77/80\n",
      "392/394 [============================>.] - ETA: 0s - loss: 0.2468 - micro_f1: 0.9548\n",
      "Epoch 00077: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2466 - micro_f1: 0.9548 - val_loss: 0.2790 - val_micro_f1: 0.9368\n",
      "Epoch 78/80\n",
      "391/394 [============================>.] - ETA: 0s - loss: 0.2466 - micro_f1: 0.9556\n",
      "Epoch 00078: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2465 - micro_f1: 0.9556 - val_loss: 0.2794 - val_micro_f1: 0.9362\n",
      "Epoch 79/80\n",
      "390/394 [============================>.] - ETA: 0s - loss: 0.2503 - micro_f1: 0.9514\n",
      "Epoch 00079: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2501 - micro_f1: 0.9518 - val_loss: 0.2798 - val_micro_f1: 0.9355\n",
      "Epoch 80/80\n",
      "389/394 [============================>.] - ETA: 0s - loss: 0.2498 - micro_f1: 0.9508\n",
      "Epoch 00080: val_micro_f1 did not improve from 0.93923\n",
      "394/394 [==============================] - 5s 12ms/step - loss: 0.2503 - micro_f1: 0.9502 - val_loss: 0.2794 - val_micro_f1: 0.9364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a8a198cc0>"
      ]
     },
     "execution_count": 135,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "#callbacks=[lrschedule_1, checkpoint_1, tensorboard_callback]\n",
    "#validation_data=((X_test_pad_seq,X_test_mask), y_test)\n",
    "#X_train_spectrogram, X_train_mask, X_test_spectrogram, X_test_mask\n",
    "opt = Adam(0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=[micro_f1])\n",
    "model.fit(x=X_train_spectrogram, y=y_train_augmented, validation_data=(X_test_spectrogram, y_test_augmented), \\\n",
    "          epochs=80, verbose=True, callbacks=[lrschedule_1, checkpoint_1, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgHfmmUUQ_kK"
   },
   "outputs": [],
   "source": [
    "!zip -r logs.zip logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "9P-2eGG5Yfoa",
    "outputId": "75dd0669-8f4e-49aa-ad86-16fb1d0782c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2828 - micro_f1: 0.9392\n",
      "Best Micro F1 score model 4= 0.9392258524894714\n"
     ]
    }
   ],
   "source": [
    "best_model_4 = tf.keras.models.load_model('BEST_MODEL_4.hdfs', custom_objects={'f1_score_micro':f1_score_micro,'micro_f1':micro_f1})\n",
    "best_f1_model_4 = best_model_4.evaluate(X_test_spectrogram, y_test_augmented)[1]\n",
    "print(\"Best Micro F1 score model 4=\", best_f1_model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "cW0xrMwpawql",
    "outputId": "41ae7e37-81ba-48e3-fcb6-19cfd4a33936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------+---------------+\n",
      "| Model no. |  Model Description   | Test Micro F1 |\n",
      "+-----------+----------------------+---------------+\n",
      "|  Model 1  |       Raw Data       |     0.125     |\n",
      "|  Model 2  |      Spectogram      |     0.9507    |\n",
      "|  Model 3  |  Raw Data Augmented  |     0.1004    |\n",
      "|  Model 4  | Spectogram Augmented |     0.9392    |\n",
      "+-----------+----------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = [\"Model no.\", \"Model Description\", \"Test Micro F1\"]\n",
    "\n",
    "pt.add_row([\"Model 1\", \"Raw Data\", round(best_f1_model_1,4)])\n",
    "pt.add_row([\"Model 2\", \"Spectogram\", round(best_f1_model_2,4)])\n",
    "pt.add_row([\"Model 3\", \"Raw Data Augmented\", round(best_f1_model_3,4)])\n",
    "pt.add_row([\"Model 4\", \"Spectogram Augmented\", round(best_f1_model_4,4)])\n",
    "\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J7OOl9hsKjA"
   },
   "source": [
    "# <font color='purple'>**Observations**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8P698oasRhZ"
   },
   "source": [
    "<ul>\n",
    "<li>The data we have is in <b>Audio format</b>. To work on audio data, we need to convert it into numeric data by <b>sampling</b> it using a sampling rate.</li>\n",
    "<li>As any audio is sequential in nature, we can make use of <b>LSTM</b> in this case. The Audios are of various lengths, however LSTM cannot work with variable length input sequences. Hence, after doing an EDA, we found that 99% of the audios are of 0.8 seconds, and so we decided to keep the max sequence length as the 0.8 seconds. Converting into the samples, it comes out to be 17640.</li>\n",
    "<li>We tried 4 different models, which are described as follows\n",
    "    <ul>\n",
    "        <li><b>Using Raw data:</b> We directly used the Raw samples from the audio. The work flow is as follows,<br>\n",
    "        <a href=\"https://imgur.com/a/P6kGhh4/\">\n",
    "         <img alt=\"Raw data\" src=\"https://i.imgur.com/AHfdECy.png\"\n",
    "         width=\"200\" height=\"300\">\n",
    "      </a> <br>\n",
    "      The raw data gave us the micro F1 score of 0.125, which is a poor score, and is almost like a random guess. \n",
    "        </li>\n",
    "        <li><b>Using Spectogram data:</b> We used the Spectrogram data from the audio. The work flow is as follows,<br>\n",
    "        <a href=\"https://imgur.com/a/BrVJkZM/\">\n",
    "         <img alt=\"Spectrogram data\" src=\"https://i.imgur.com/yBEDu8i.png\"\n",
    "         width=\"250\" height=\"500\">\n",
    "      </a><br>\n",
    "      As we didn't get good enough F1 score using only the raw data, now we used the spectrogram data of the audios. The spectrogram data gave us the micro F1 score of 0.9507, which is a very good score.</li>\n",
    "        <li><b>Augmenting Raw data:</b> We used the Augmented Raw samples from the audio. The work flow is as follows,<br>\n",
    "        <a href=\"https://imgur.com/a/OmlUH06/\">\n",
    "         <img alt=\"Augmented Raw data\" src=\"https://i.imgur.com/PwWXZYZ.png\"\n",
    "         width=\"200\" height=\"400\">\n",
    "      </a><br>\n",
    "      We tried to augment the raw data in this model. It gave us the micro F1 score of 0.1004, which is a poor score, and is almost like a random guess. </li>\n",
    "        <li><b>Augmenting Spectogram data:</b> We used the Augmented Spectrogram data from the audio. The work flow is as follows,<br>\n",
    "        <a href=\"https://imgur.com/a/FUCowY2/\">\n",
    "         <img alt=\"Augmented Spectrogram data\" src=\"https://i.imgur.com/M6EIra4.png\"\n",
    "         width=\"250\" height=\"500\">\n",
    "      </a><br>\n",
    "      As we didn't get good enough F1 score using only the augmented raw data, now we augmented the spectrogram data of the audios. The augmented spectrogram data gave us the micro F1 score of 0.9392, which is a very good score.</li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li><b>Why does Spectrogram give better results?</b>\n",
    "    <ul>\n",
    "        <li>We saw that Spectrogram data of the audio is giving us better results as compared to using plain raw samples from the audio. This is because te spectrogram gives us a rich set of information/features such as pitch difference, volume, overtone, etc. which can help us better differentiate what is said in the audio. Whereas, the audio sampling (raw data) does not give us any of that information, and is just a series of numbers with no inherant features. </li>\n",
    "    </ul>\n",
    "</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Speech detection Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0058c742827f431596a0188606863ddf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_477852c6372a46edb6eb9f3c8ad99adb",
       "IPY_MODEL_00f0f02d35f34fb3b9f6b869cc44214a"
      ],
      "layout": "IPY_MODEL_6447d1f9ba9845b5b478894aa2da2244"
     }
    },
    "00f0f02d35f34fb3b9f6b869cc44214a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59bb92fb80c64ca59126d96514c56ea4",
      "placeholder": "",
      "style": "IPY_MODEL_c7aebf186254440f8053e0d442a1493f",
      "value": " 1400/1400 [00:15&lt;00:00, 92.12it/s]"
     }
    },
    "0162b6b058934c09aad8f1a6bc33b2e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "031ecba5576d4a97a1e08db7ac648c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "035f1d8993324ca2a445c7c2710d2fa5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0869af9fb4c84379a87340845cfaa244": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4cae1fe1c1d44ecba6b70cdcbd7c072",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_031ecba5576d4a97a1e08db7ac648c6a",
      "value": 1
     }
    },
    "0d5a84aad0f64c7eadf7f79386eca78e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ee435d4708540f19aa66cf46338c4a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f00f5a08c0b4193b83f9cd63ee838cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10fd7456dbaf4ce3a2bafadad598902c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8a039fa1fb743f398c4bccc7824f477",
       "IPY_MODEL_559bde2d34df4679aaa4e61c2fd12856"
      ],
      "layout": "IPY_MODEL_6541802d06a349428b4b16c598bfe3f0"
     }
    },
    "14146a9d152d47b68fa65271249a5873": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d88c9980d46748f982799bb1e70cb80e",
       "IPY_MODEL_a6ac3d4d86df4fe68a72e88944958932"
      ],
      "layout": "IPY_MODEL_94822acdae644145a1695e259cca3a68"
     }
    },
    "15dceace35794ea481136f3190fc9d23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7cbc4fda21c4031a80789417099fbaf",
      "placeholder": "",
      "style": "IPY_MODEL_ecb0d59941ff45b5afa83681c14e45d5",
      "value": " 600/? [19:35&lt;00:00,  1.96s/it]"
     }
    },
    "20920ce1cf714469bfaf3bc0d0dc5250": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20e0771214ce43d48c1956541975ff15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21b558eeb41641fc8e9aca53f1f54acd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75bcf38542a44017828f85386d0b5c81",
      "placeholder": "",
      "style": "IPY_MODEL_583178cee17d4f3a9d801dadd45a6f7e",
      "value": " 1400/1400 [10:45&lt;00:00,  2.17it/s]"
     }
    },
    "21f9a7b24f324dabacc5bdd2dd2aa951": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "240eaf674b75467dafcf3f56f7d316aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30682612f8cb4a56811a0fd0f01d3f70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "308c7145de9a4a59bf71863ea06cb69a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36ae6015f4234b47a71608de2d50056c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebaa5ac8c77a423a968caf2fb303404e",
       "IPY_MODEL_21b558eeb41641fc8e9aca53f1f54acd"
      ],
      "layout": "IPY_MODEL_76c8871ca47543408de273192ceb5beb"
     }
    },
    "3cca56fa5ee44afc9ba574859e7f9e78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d7b729bb25b4c0085f5ec3f2c28b2e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fd96e3889914e7b85747acf583b7707": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ee435d4708540f19aa66cf46338c4a4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4aec3b6322fb4420bb16e2ba15130e44",
      "value": 1
     }
    },
    "40cb533aff9648768b5a4c70511dcab1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4237a39d5ccb4cfdb676bc0a2f60f177": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_035f1d8993324ca2a445c7c2710d2fa5",
      "placeholder": "",
      "style": "IPY_MODEL_0f00f5a08c0b4193b83f9cd63ee838cb",
      "value": " 600/600 [00:07&lt;00:00, 80.89it/s]"
     }
    },
    "43bc91939ea2410db48b78e993dbdb69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0869af9fb4c84379a87340845cfaa244",
       "IPY_MODEL_b9d4f8d79e4944db9830d460fc06a74f"
      ],
      "layout": "IPY_MODEL_9f579ab2ebfc42109b9c3e6ed14368aa"
     }
    },
    "477852c6372a46edb6eb9f3c8ad99adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9852c5369234c0ba459e0c374ab5e02",
      "max": 1400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ae570077bf34817a4bdb4949d3a16c5",
      "value": 1400
     }
    },
    "4aad82199c424733ab12b4d3a722af9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20920ce1cf714469bfaf3bc0d0dc5250",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f90dccdbcc84952b5bed25d8bfc91e3",
      "value": 1
     }
    },
    "4aec3b6322fb4420bb16e2ba15130e44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4cb7a749fdc14d158016ca6a06809cf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bd00b4728f04843855805d3a0209fe6",
      "placeholder": "",
      "style": "IPY_MODEL_81eb5de39fbc4682a1e3eb2ea718faab",
      "value": " 12600/12600 [09:56&lt;00:00, 21.13it/s]"
     }
    },
    "4f35e03f769a437ab5af7427b353da30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee402e09cb084d588db7d9ea204ede13",
      "placeholder": "",
      "style": "IPY_MODEL_f5b1648d78d34a1ea86e03c1d2f4e9b7",
      "value": " 1400/? [18:30&lt;00:00,  1.26it/s]"
     }
    },
    "559bde2d34df4679aaa4e61c2fd12856": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1d281855501473eb4ecc8f10215e549",
      "placeholder": "",
      "style": "IPY_MODEL_3cca56fa5ee44afc9ba574859e7f9e78",
      "value": " 600/600 [08:03&lt;00:00,  1.24it/s]"
     }
    },
    "583178cee17d4f3a9d801dadd45a6f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59bb92fb80c64ca59126d96514c56ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ae570077bf34817a4bdb4949d3a16c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6447d1f9ba9845b5b478894aa2da2244": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6541802d06a349428b4b16c598bfe3f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69ad04d1988f40ad8928b48c3852f1cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bd00b4728f04843855805d3a0209fe6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "725f60dec5f04bf0a65ddab5293cb6fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "754ee104f3924bba861c865745bab31c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75bcf38542a44017828f85386d0b5c81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76c8871ca47543408de273192ceb5beb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c88c3a1a4274107aa3ab74d0e7c9ed0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81eb5de39fbc4682a1e3eb2ea718faab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8229cf19c28348bd92315628a6e6796c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_240eaf674b75467dafcf3f56f7d316aa",
      "max": 12600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec2a993df3214831be3e35882f4f0faf",
      "value": 12600
     }
    },
    "9181d8ad6d8748dfa3e91b6e221b7a02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0162b6b058934c09aad8f1a6bc33b2e4",
      "placeholder": "",
      "style": "IPY_MODEL_308c7145de9a4a59bf71863ea06cb69a",
      "value": " 600/? [07:27&lt;00:00,  1.34it/s]"
     }
    },
    "94822acdae644145a1695e259cca3a68": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9752d761145f48f99550a3b3891866f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4aad82199c424733ab12b4d3a722af9e",
       "IPY_MODEL_9181d8ad6d8748dfa3e91b6e221b7a02"
      ],
      "layout": "IPY_MODEL_20e0771214ce43d48c1956541975ff15"
     }
    },
    "98063d8d4a574fada648d8c56d8cab88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "986386b7a8b4483999e233c91175065e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9ed01f09e4924d4897de2c8e2aa35e07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f579ab2ebfc42109b9c3e6ed14368aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f90dccdbcc84952b5bed25d8bfc91e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a6ac3d4d86df4fe68a72e88944958932": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98063d8d4a574fada648d8c56d8cab88",
      "placeholder": "",
      "style": "IPY_MODEL_9ed01f09e4924d4897de2c8e2aa35e07",
      "value": " 5400/5400 [08:45&lt;00:00, 10.28it/s]"
     }
    },
    "a7a22410247942899f7d253fa81aa6cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad9bf13f0bdf4e4a84da72d728671189": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fd96e3889914e7b85747acf583b7707",
       "IPY_MODEL_15dceace35794ea481136f3190fc9d23"
      ],
      "layout": "IPY_MODEL_7c88c3a1a4274107aa3ab74d0e7c9ed0"
     }
    },
    "b1d281855501473eb4ecc8f10215e549": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b43e41140732486aa02953c65d757eb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b4cae1fe1c1d44ecba6b70cdcbd7c072": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b53dbad588144d60a9b4814baa6beadf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6b66b57dee1432284403efc726c9695",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d73225e3835340e19d23aeb04e236a2c",
      "value": 1
     }
    },
    "b9191a5e73854e5aa2a5cee1946a044a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b9d4f8d79e4944db9830d460fc06a74f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d5a84aad0f64c7eadf7f79386eca78e",
      "placeholder": "",
      "style": "IPY_MODEL_21f9a7b24f324dabacc5bdd2dd2aa951",
      "value": " 1400/? [32:21&lt;00:00,  1.39s/it]"
     }
    },
    "be099a8dc7804a2aa32f0f921aa37e2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d735fc20e3084576ade2c492e4cbc4f4",
       "IPY_MODEL_4237a39d5ccb4cfdb676bc0a2f60f177"
      ],
      "layout": "IPY_MODEL_c84c5c617c124473b362bb59fa2cb71d"
     }
    },
    "c6b66b57dee1432284403efc726c9695": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7aebf186254440f8053e0d442a1493f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c84c5c617c124473b362bb59fa2cb71d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d73225e3835340e19d23aeb04e236a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d735fc20e3084576ade2c492e4cbc4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69ad04d1988f40ad8928b48c3852f1cc",
      "max": 600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_986386b7a8b4483999e233c91175065e",
      "value": 600
     }
    },
    "d88c9980d46748f982799bb1e70cb80e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7a22410247942899f7d253fa81aa6cc",
      "max": 5400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b43e41140732486aa02953c65d757eb8",
      "value": 5400
     }
    },
    "d9852c5369234c0ba459e0c374ab5e02": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7cbc4fda21c4031a80789417099fbaf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8a039fa1fb743f398c4bccc7824f477": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40cb533aff9648768b5a4c70511dcab1",
      "max": 600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30682612f8cb4a56811a0fd0f01d3f70",
      "value": 600
     }
    },
    "ebaa5ac8c77a423a968caf2fb303404e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d7b729bb25b4c0085f5ec3f2c28b2e6",
      "max": 1400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9191a5e73854e5aa2a5cee1946a044a",
      "value": 1400
     }
    },
    "ec2a993df3214831be3e35882f4f0faf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ecb0d59941ff45b5afa83681c14e45d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee402e09cb084d588db7d9ea204ede13": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5b1648d78d34a1ea86e03c1d2f4e9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f78acd4f487a441c8df95e5676e366d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b53dbad588144d60a9b4814baa6beadf",
       "IPY_MODEL_4f35e03f769a437ab5af7427b353da30"
      ],
      "layout": "IPY_MODEL_754ee104f3924bba861c865745bab31c"
     }
    },
    "fe6a57c7ecd64948a5c51d342b291c89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8229cf19c28348bd92315628a6e6796c",
       "IPY_MODEL_4cb7a749fdc14d158016ca6a06809cf8"
      ],
      "layout": "IPY_MODEL_725f60dec5f04bf0a65ddab5293cb6fd"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
